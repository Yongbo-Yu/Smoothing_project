In many  applications, the quantity of interest is usually expressed as 
\begin{equation}\label{eq:QoI}
\expt{g(X)},
\end{equation}
where  $X$ is a certain stochastic process and $g$ is an observable of the state  process $X$.

For instance, in quantitative finance,   the price of an option on an underlying $S$ can typically- disregarding discounting-be expressed as \eqref{eq:QoI}, for some (payoff) function $g$ on $S$ and the expectation operator $E$ induced by the appropriate pricing measure. 

Approximating  \eqref{eq:QoI} is usually challenging due to a combination of two complications
\begin{itemize}
\item $X$ often takes values in a high-dimensional state space.  For instance in computational finance the reason for the high dimensionality may be the time-discretization of a stochastic differential equation,  path dependence of the option (i.e., $S$ is actually a path of an asset price, not the value at a specific time), a large number of underlying assets, or others.
\item The payoff function $g$ is  not smooth. In fact,  in many cases, the  integrand contains either kinks or jumps. For instance, in the context of option pricing,  an option is normally considered worthless if the value falls below a predetermined strike price.  A kink  (discontinuity in the gradients) is present when the payoff function is  continuous such as the case of digital option with payoff function $g$ being the indicator function. On the other hand, a jump  exists  when the function is discontinuous itself, for instance, this is the case when approximating densities and thus $g$ is represented by the Dirac Delta function in that case. 
\end{itemize}
There are mainly two approaches for approximating \eqref{eq:QoI}
\begin{enumerate}
\item The first approach treats problem \eqref{eq:QoI} as a stochastic problem and relies  on Monte Carlo (MC) methods (standard MC, Multilevel Monte Carlo (MLMC) \cite{giles2015multilevel}, etc \dots) to approximate the expectation in \eqref{eq:QoI}.  Although, standard Monte Carlo complexity  is insensitive to both the dimension and the regularity of $g$, it has a very slow rate of convergence. On the other hand, MLMC, which is based on hierarchical representation of the expectation and has a better complexity than standard MC,  is highly affected by the low regularity of $g$, due to its effect on i) the strong convergence rate and ii) the kurtosis. For instance, when $g$ is  either the Dirac delta or the indicator functions, standard MLMC  fail or not has the optimal performance, due to the singularity present in $g$, that causes  i) high variance, ii) low strong convergence rate and iii) high kurtosis for the MLMC estimator. 

In the literature, few works tried to address this issue. For instance, Avikainen in \cite{avikainen2009irregular}, and Giles, Higham, and Mao in \cite{giles2009analysing} used MLMC for such a task without smoothing and obtained bad performance for MLMC estimator.  On the other hand, a second approach  was suggested in  \cite{giles2008improved,giles2013numerical}, that used implicit smoothing based on the use of conditional expectations. There are two potential issues  with this second approach: i) In general cases, one may have dynamics where it is not easy to derive an  analytic expression for the conditional expectation and ii) This approach used a higher order scheme, that is the Milstein scheme, to improve the strong order of convergence, and consequently the complexity of the MLMC estimator. Such a scheme becomes very computationally expensive for higher dimensional dynamics. Different non smooth payoff functions were considered in \cite{giles2008improved,giles2013numerical} (Asian, barrier, digital)  but the only considered dynamics were under the GBM model. Finally, in \cite{giles2015multilevel}, the authors suggested a different approach based on parametric smoothing.  In fact, they carefully constructed a regularized version of the QoI, based on a  regularization parameter that depends on the weak and strong convergence rates and also  the tolerance requirement.  This approach, despite offering better performance for the MLMC estimator and a better setting for theoretical analysis, it has the practical disadvantage consisting in the difficulty of generalizing it to cases where there is no prior knowledge of the  convergence rates (that is they need to be estimated numerically), and also for each error tolerance, a new  regularization parameter needs to be computed. Note also that all the numerical examples in \cite{giles2015multilevel} were based on the GBM dynamics.

In this work, we address a similar problem and  propose an alternative approach that is  based on numerical smoothing. The numerical smoothing idea is based on i) finding lines or areas of discontinuity using root finding algorithms such Newton algorithm, ii)  employing suitable transformations of the integration domain, and iii) a pre-integration (smoothing) step with respect to the dimension containing the kink/jump. Compared to previous mentioned works, our approach   can be easily applied to cases where one can not apply analytic smoothing. Furthermore,  we obtain similar  rates of strong convergence and MLMC complexity  as in  \cite{giles2008improved,giles2013numerical}, without the need to use higher order schemes such as Milstein scheme. In addition,  our approach is parameter free compared to that of  \cite{giles2015multilevel}. Therefore, in practice it is much easier to apply for any dynamics and QoI. Finally, compared to \cite{giles2008improved,giles2013numerical,giles2015multilevel}, we add numerical results for the Heston model were discretization is needed unlike the GBM dynamics which is considered here as a toy example.
\item A second approach considers \eqref{eq:QoI} as an integration problem, and relies on deterministic quadrature methods (sparse grids quadrature (SGQ) \cite{bungartz2004sparse}, adaptive sparse grids quadrature(ASGQ) \cite{haji2016multi}, quasi Monte Carlo \cite{niederreiter1992random}, etc, \dots) to approximate the integral arising from  \eqref{eq:QoI}.   The high dimension of the approximated integrals can be treated with dimension-adaptive quadrature methods to have the desired convergence behavior. However, the existence of kinks or jumps in the integrand  heavily degrades the performance of quadrature formulas.  Despite the  significant progress in SGQ methods \cite{bungartz2004sparse} for high dimensional integration  of  smooth integrands, few works have been done to deal with  cases involving integrands with kinks or jumps. 

Some works \cite{griebel2013smoothing,bayersmoothing, griebel2017note,griewank2017high,xiao2018conditional} addressed similar kind of problems, characterized by the presence of kinks and jumps,  but with much more emphasis on Quasi Monte Carlo (QMC). In \cite{griebel2013smoothing, griebel2017note,griewank2017high}, an  analysis of the performance of  Quasi Monte Carlo (QMC) and SGQ methods has been conducted, in the presence of kinks and jumps.  In \cite{griebel2013smoothing,griebel2017note}, the authors studied the terms of the ANOVA decomposition of functions with kinks defined on $d$-dimensional Euclidean space $\rset^d$, and showed   that under some assumptions all but the the highest order ANOVA term  of the $2^d$ ANOVA terms can be smooth for the case of an arithmetic Asian option with the Brownian bridge construction. Furthermore, \cite{griewank2017high} extended the work in \cite{griebel2013smoothing,griebel2017note} from kinks
to jumps for  the case of an arithmetic average digital Asian option with the principal component analysis (PCA). The main findings in \cite{griebel2013smoothing,griebel2017note} was obtained  for an  integrand  of the form $f(\mathbf{x}) = \max(\phi(\mathbf{x}), 0)$ with $\phi$ being smooth. In fact, by assuming  i) the $d$-dimensional function $\phi$ has a positive partial derivative with respect to $x_j$ for some $j \in \{1,\dots,d\}$, ii) certain growth conditions at infinity are satisfied, the authors showed that the ANOVA terms of $f$ that do not depend on the variable $x_j$ are smooth.   We note that \cite{griebel2013smoothing,griebel2017note,griewank2017high} focus  more on  theoretical aspects of applying QMC in such a setting. On the other hand, we focus more on  specific practical problems, where we add the adaptivity paradigm to the picture.

On the other hand, other works \cite{bayersmoothing,xiao2018conditional,bayer2018hierarchical} address the low regularity of the integrand by performing analytic smoothing based conditional expectation tools, before applying quadrature methods. For instance,    \cite{xiao2018conditional} addresses similar kind of problems using QMC. Being very much related to \cite{bayersmoothing}, the authors i) assume that the conditional expectation can be computed explicitly, by imposing very strong assumptions. ii) Secondly, they  use  PCA on the gradients to reduce the effective dimension. In our work, we do not make such strong assumptions, which is why we need numerical methods, more precisely root finding and the quadrature in the first direction.

In this work, we are interested in solving this problem  by using adaptive  sparse grids quadrature (ASGQ) methods coupled with suitable transformations. The main idea is to find lines or areas of discontinuity and to employ suitable transformations of the integration domain. Then  by a pre-integration (smoothing) step with respect to the dimension containing the kink/jump,  we end up with integrating  only over the smooth parts of the integrand and the fast convergence of ASGQ can be regained.
\end{enumerate}



