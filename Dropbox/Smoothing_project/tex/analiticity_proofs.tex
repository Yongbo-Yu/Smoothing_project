\subsection{Haar construction of Brownian motion revisited}
\label{sec:haar-constr-brown}

For simplicity we shall assume throughout that we work on a fixed time
interval $[0,T]$ with $T = 1$.

With the Haar mother wavelet
\begin{equation}
  \label{eq:Haar-mother}
  \psi(t) \coloneqq
  \begin{cases}
    1, & 0 \le t < \half, \\
    -1, & \half \le t < 1, \\
    0, & \text{else},
  \end{cases}
\end{equation}
we construct the Haar basis of $L^2\left([0,1] \right)$ by setting
\begin{subequations}
  \label{eq:Haar-basis}
  \begin{gather}
    \label{eq:Haar-constant}
    \psi_{-1}(t) \coloneqq \indic{[0,1]}(t), \\
    \label{eq:Haar-nonconstant}
    \psi_{n,k}(t) \coloneqq 2^{n/2} \psi\left( 2^n t - k \right), \quad n \in
    \N_0, \ k = 0, \ldots, 2^n-1.
  \end{gather}
\end{subequations}
We note that $\supp \psi_{n,k} = [2^{-n}k, 2^{-n}(k+1)]$. Moreover, we define
a grid $\mathcal{D}^n \coloneqq \Set{t^n_\ell \mid \ell = 0, \ldots, 2^{n+1}}$ by
$t^n_\ell \coloneqq \f{\ell}{2^{n+1}}$. Notice that the Haar functions up to level
$n$ are piece-wise constant with points of discontinuity given by
$\mathcal{D}^n$.

Next we define the antiderivatives of the basis functions
\begin{subequations}
  \label{eq:Haar-int-basis}
  \begin{gather}
    \label{eq:Haar-int-constant}
    \Psi_{-1}(t) \coloneqq \int_0^t \psi_{-1}(s) ds, \\
    \label{eq:Haar-int-nonconstant}
    \Psi_{n,k}(t) \coloneqq \int_0^t \psi_{n,k}(s) ds.
  \end{gather}
\end{subequations}
For an i.i.d.~set of standard normal random variables (\emph{coefficients})
$Z_{-1}$, $Z_{n,k}$, $n \in \N_0$, $k = 0, \ldots, 2^n-1$, we can then define
a standard Brownian motion
\begin{equation}
  \label{eq:Brownian-motion}
  W_t \coloneqq Z_{-1} \Psi_{-1}(t) + \sum_{n=0}^\infty \sum_{k=0}^{2^n-1}
  Z_{n,k} \Psi_{n,k}(t),
\end{equation}
and the truncated version
\begin{equation}
  \label{eq:Brownian-motion-truncated}
  W_t^N \coloneqq Z_{-1} \Psi_{-1}(t) + \sum_{n=0}^N \sum_{k=0}^{2^n-1}
  Z_{n,k} \Psi_{n,k}(t).
\end{equation}
Note that $W^N$ already coincides with $W$ along the grid $\mathcal{D}^N$. We
define the corresponding increments for any function or process $F$ by
\begin{equation}
  \label{eq:increments}
  \Delta^N_\ell F \coloneqq F(t^N_{\ell+1}) - F(t^N_\ell).
\end{equation}

\subsection{Stochastic differential equations}
\label{sec:stoch-diff-equat}

For simplicity we consider a one-dimensional SDE $X$ given by
\begin{equation}
  \label{eq:SDE}
  dX_t = b(X_t) dW_t, \quad X_0 = x \in \R.
\end{equation}
We assume that $b$ is bounded and has bounded derivatives of all
orders. Recall that we want to compute
\begin{equation*}
  E\left[ g\left( X_T \right) \right]
\end{equation*}
for some function $g : \R \to \R$ which is not necessarily smooth.
We also define the solution of the Euler scheme along the grid $\mathcal{D}^N$
by $X^N_0 \coloneqq X_0 = x$ and
\begin{equation}
  \label{eq:euler}
  X^N_{\ell+1} \coloneqq X^N_\ell + b\left( X^N_{\ell} \right) \Delta^N_\ell W.
\end{equation}
For convenience, we also define $X^N_T \coloneqq X^N_{2^N}$.

Clearly, the random variable $X^N_\ell$ is a deterministic function of the
random variables $Z_{-1}$ and $Z^N \coloneqq \left(Z_{n,k} \right)_{n=0,
  \ldots, N, \ k=0, \ldots 2^n-1}$. Abusing notation, let us therefore write
\begin{equation*}
  X^N_\ell = X^N_\ell\left(Z_{-1}, Z^N \right)
\end{equation*}
for the appropriate (now deterministic) map $X^N_\ell: \R \times
\R^{2^{N+1}-1} \to \R$. We shall write $y \coloneqq z_{-1}$ and $z^N$ for the
(deterministic) arguments of the function $X^N_\ell$.

A note of caution is in order regarding convergence as $N \to \infty$: while
the sequence of random processes $X^N_\cdot$ converges to the solution
of~\eqref{eq:SDE} (under the usual assumptions on $b$), this is not true in
any sense for the deterministic functions.

Define
\begin{equation}
  \label{eq:H-function}
  H^N(z^N) \coloneqq E\left[ g\left( X^N_T\left( Z_{-1}, z^N \right) \right) \right].
\end{equation}
We claim that $H^N$ is analytic.

Let us consider a mollified version $g_\delta$ of $g$ and the corresponding
function $H^N_\delta$ (defined by replacing $g$ with $g_\delta$
in~\eqref{eq:H-function}). Tacitly assuming that we can interchange
integration and differentiation, we have
\begin{equation*}
  \f{\pa H^N_\delta(z^N)}{\pa z_{n,k}} = E\left[ g_\delta^\prime\left( X^N_T\left( Z_{-1},
    z^N \right) \right) \f{\pa X^N_T(Z_{-1}, z^N)}{\pa z_{n,k}}\right].
\end{equation*}
Multiplying and dividing by $\f{\pa X^N_T(Z_{-1}, z^N)}{\pa y}$ and replacing
the expectation by an integral w.r.t.~the standard normal density, we obtain
\begin{equation}
  \label{eq:1}
  \f{\pa H^N_\delta(z^N)}{\pa z_{n,k}} = \int_\R \f{\pa g_\delta\left( X^N_T
      (y, z^N) \right)}{\pa y} \left( \f{\pa X^N_T}{\pa y}(y, z^N)
  \right)^{-1} \f{\pa X^N_T}{\pa z_{n,k}}(y, z^N) \f{1}{\sqrt{2\pi}}
  e^{-\f{y^2}{2}} dy.
\end{equation}

If we are able to do integration by parts, then we can get rid of the
mollification and obtain smoothness of $H^N$ since we get
\begin{equation*}
  \f{\pa H^N(z^N)}{\pa z_{n,k}} = -\int_\R g\left( X^N_T
      (y, z^N) \right) \f{\pa}{\pa y} \left[ \left( \f{\pa X^N_T}{\pa y}(y, z^N)
  \right)^{-1} \f{\pa X^N_T}{\pa z_{n,k}}(y, z^N) \f{1}{\sqrt{2\pi}}
  e^{-\f{y^2}{2}}\right] dy.
\end{equation*}

We realize that there is a potential problem looming in the inverse of the
derivative w.r.t.~$y$.\footnote{Let us assume that
  $X^N_T(y,z^N) = \cos(y) + z_{n,k}$. Then~\eqref{eq:1} is generally not
  integrable.} Before we continue, let us introduce the following notation:
for sequences of random variables $F_N, G_N$ we say that
$F_N = \mathcal{O}(G_N)$ if there is a random variable $C$ with finite moments
of all orders such that for all $N$ we have $\abs{F_N} \le C \abs{G_N}$ a.s.

\begin{assumption}
  \label{ass:boundedness-derivative}
  There are positive random variables $C_p$ with finite moments of all orders
  such that
  \begin{equation*}
    \forall N \in \N,\ \forall \ell_1, \ldots, \ell_p \in \{0, \ldots, 2^N-1\}:\ \abs{\f{\pa^p
        X^N_T}{\pa X^N_{\ell_1} \cdots \pa X^N_{\ell_p}}} \le C_p \text{ a.s.}
  \end{equation*}
  In terms of the above notation, that means that $\f{\pa^p X^N_T}{\pa
    X^N_{\ell_1} \cdots \pa X^N_{\ell_p}} = \mathcal{O}(1)$.
\end{assumption}

\begin{remark}
  It is probably hard to argue that a deterministic constant $C$ may exist.
\end{remark}

Assumption~\ref{ass:boundedness-derivative} is natural, but now we need to
make a much more serious assumption, which is probably difficult to verify in
practice.

\begin{assumption}
  \label{ass:boundedness-inverse}
  For any $p \in \N$ we have that
  \begin{equation*}
    \left( \f{\pa X^N_T}{\pa y}\left( Z_{-1}, Z^N \right) \right)^{-p} = \mathcal{O}(1).
  \end{equation*}
\end{assumption}

\begin{lemma}
  \label{lem:dXdZ}
  We have
  \begin{equation*}
    \f{\pa X^N_T}{\pa z_{n,k}}(Z_{-1}, Z^N) = 2^{-n/2+1} \mathcal{O}(1)
  \end{equation*}
  in the sense that the $\mathcal{O}(1)$ term does not depend on $n$ or $k$.
\end{lemma}
\begin{proof}
  First let us note that Assumption~\ref{ass:boundedness-derivative} implies
  that $\f{\pa X^N_T}{\pa \Delta^N_\ell W} = \mathcal{O}(1)$. Indeed, we have
  \begin{equation*}
    \f{\pa X^N_T}{\pa \Delta^N_\ell W} = \f{\pa X^N_T}{\pa X^N_{\ell+1}}
    \f{\pa X^N_{\ell+1}}{\pa \Delta^N_\ell W} = \mathcal{O}(1) b(X^N_\ell) =
    \mathcal{O}(1).
  \end{equation*}
  Next we need to understand which increments $\Delta^N_\ell$ do depend on
  $Z_{n,k}$. This is the case iff $\supp \psi_{n,k}$ has a non-empty
  intersection with $]t^N_{\ell}, t^N_{\ell+1}[$. Explicitly, this means that
  \begin{equation*}
    \ell 2^{-(N-n+1)} -1 < k < (\ell+1) 2^{-(N-n+1)}.
  \end{equation*}
  If we fix $N$, $k$, $n$, this means that the derivative of $\Delta^N_\ell W$
  w.r.t.~$Z_{n,k}$ does not vanish iff
  \begin{equation*}
    2^{N-n+1} k \le \ell < 2^{N-n+1} (k+1).
  \end{equation*}
  Noting that
  \begin{equation}\label{eq:dWdZ}
    \abs{\f{\pa \Delta^N_\ell W}{\pa Z_{n,k}}} = \abs{\Delta^N_\ell \Psi_{n,k}}
    \le 2^{-(N-n/2)},
  \end{equation}
  we thus have
  \begin{equation}
    \label{eq:2}
    \f{\pa X^N_T}{\pa z_{n,k}}(Z_{-1}, Z^N) =
    \sum_{\ell=2^{N-n+1}k}^{2^{N-n+1}(k+1)-1} \f{\pa X^N_T}{\pa \Delta^N_\ell
      W} \f{\pa \Delta^N_\ell W}{\pa Z_{n,k}} = 2^{N-n+1} 2^{-(N-n/2)}
    \mathcal{O}(1) = 2^{-n/2+1} \mathcal{O}(1).\qedhere
  \end{equation}
\end{proof}

\begin{lemma}
  \label{lem:d2XdZdY}
  In the same sense as in Lemma~\ref{lem:dXdZ} we have
  \begin{equation*}
    \f{\pa^2 X^N_T}{\pa y \pa z_{n,k}}(Z_{-1}, Z^N) = 2^{-n/2+1} \mathcal{O}(1).
  \end{equation*}
\end{lemma}
\begin{proof}
  $\Delta^N_\ell W$ is a linear function in $Z_{-1}$ and $Z^N$, implying that
  all mixed derivatives $\f{\pa^2\Delta^N_\ell W}{\pa Z_{n,k} \pa Z_{-1}}$ vanish.
  From equation~\eqref{eq:2} we hence see that
  \begin{equation*}
    \f{\pa^2 X^N_T}{\pa z_{n,k} \pa y}(Z_{-1}, Z^N) =
    \sum_{\ell=2^{N-n+1}k}^{2^{N-n+1}(k+1)-1} \f{\pa^2 X^N_T}{\pa \Delta^N_\ell
      W \pa Z_{-1}} \f{\pa \Delta^N_\ell W}{\pa Z_{n,k} }.
  \end{equation*}
  Further,
  \begin{equation*}
    \f{\pa^2 X^N_T}{\pa \Delta^N_\ell W \pa Z_{-1}} = \sum_{j=0}^{2^{N+1}-1}
    \f{\pa^2 X^N_T}{\pa \Delta^N_\ell W \pa \Delta^N_j W} \f{\pa \Delta^N_j W}{\pa
      Z_{-1}}.
  \end{equation*}
  Note that
  \begin{equation}
    \label{eq:d2XdWdW}
    \f{\pa^2 X^N_T}{\pa \Delta^N_\ell W \pa \Delta^N_j W} = \f{\pa^2
      X^N_T}{\pa X^N_{\ell+1} \pa X^N_{j+1}} b(X^N_\ell) b(X^N_j) + \indic{j
      < \ell} \f{\pa X^N_T}{\pa X_\ell^N} b^\prime(X^N_\ell) \f{\pa
      X^N_\ell}{\pa X^N_{j+1}} b(X^N_j) = \mathcal{O}(1)
  \end{equation}
  by Assumption~\ref{ass:boundedness-derivative}. We also have $\f{\pa \Delta^N_j W}{\pa
    Z_{-1}} = \mathcal{O}(2^{-N})$, implying the statement of the lemma.
\end{proof}

\begin{remark}
  Lemma~\ref{lem:dXdZ} and~\ref{lem:d2XdZdY} also hold (mutatis mutandis) for
  $z_{n,k} = y$ (with $n = 0$).  
\end{remark}

\begin{proposition}
  \label{prop:first-derivatives}
  We have $\f{\pa H^N(z^N)}{\pa z_{n,k}} = \mathcal{O}(2^{-n/2})$ in the sense
  that the constant in front of $2^{-n/2}$ does not depend on $n$ or $k$.
\end{proposition}
\begin{proof}
  We have
  \begin{align*}
    \f{\pa H^N(z^N)}{\pa z_{n,k}} &= -\int_\R g\left( X^N_T
      (y, z^N) \right) \f{\pa}{\pa y} \left[ \left( \f{\pa X^N_T}{\pa y}(y, z^N)
  \right)^{-1} \f{\pa X^N_T}{\pa z_{n,k}}(y, z^N)  \f{1}{\sqrt{2\pi}}
                                    e^{-\f{y^2}{2}} \right] dy\\
    &= -\int_\R g\left( X^N_T(y, z^N) \right) \Biggl[- \left( \f{\pa
      X^N_T}{\pa y}(y, z^N) \right)^{-2} \f{\pa^2 X^N_T}{\pa y^2}(y, z^N)
      \f{\pa X^N_T}{\pa z_{n,k}}(y, z^N) +\\
    &\quad+ \left( \f{\pa X^N_T}{\pa y}(y, z^N) \right)^{-1} \f{\pa^2
      X^N_T}{\pa z_{n,k} \pa y}(y, z^N) - y \left( \f{\pa X^N_T}{\pa y}(y, z^N)
  \right)^{-1} \f{\pa X^N_T}{\pa z_{n,k}}(y, z^N) \Biggr] \f{1}{\sqrt{2\pi}}
                                    e^{-\f{y^2}{2}}dy.
  \end{align*}
  Notice that when $F^N(Z_{-1}, Z^N) = \mathcal{O}(c)$ for some deterministic
  constant $c$, then this property is retained when integrating out one of the
  random variables, i.e., we still have
  \begin{equation*}
    \int_\R F^N(y, Z^N) \f{1}{\sqrt{2\pi}} e^{-\f{y^2}{2}}dy = \mathcal{O}(c).
  \end{equation*}
  Hence, Lemma~\ref{lem:dXdZ} and Lemma~\ref{lem:d2XdZdY} together with
  Assumption~\ref{ass:boundedness-inverse} (for $p=2$) imply that
  \begin{equation*}
    \f{\pa H^N(z^N)}{\pa z_{n,k}} = \mathcal{O}(2^{-n/2})
  \end{equation*}
  with constants independent of $n$ and $k$.
\end{proof}

For the general case we need
\begin{lemma}
  \label{lem:d2XdZ2}
  For any $p \in \N$ and indices $n_1, \ldots, n_p$ and $k_1, \ldots, k_p$
  (satisfying $0 \le k_j < 2^{n_j}$) we have (with constants independent from
  $n_j, k_j$)
  \begin{equation*}
    \f{\pa^p X^N_T}{\pa z_{n_1,k_1} \cdots \pa z_{n_p,k_p}} (Z_1, Z^N) =
    \mathcal{O}\left( 2^{-\sum_{j=1}^p n_j/2} \right).
  \end{equation*}
  The result also holds (mutatis mutandis) if one or several $z_{n_j,k_j}$ are
  replaced by $y = z_{-1}$ (with $n_j$ set to $0$).
\end{lemma}
\begin{proof}
  We start noting that each $\Delta^N_\ell W$ is a linear function of
  $(Z_{-1},Z^N)$ implying that all higher derivatives of $\Delta^N_\ell W$
  w.r.t.~$(Z_{-1},Z^N)$ vanish. Hence,
  \begin{equation*}
    \f{\pa^p X^N_T}{\pa Z_{n_1,k_1} \cdots \pa Z_{n_p,k_p}} = \sum_{\ell_1 =
      2^{N-n_1+1} k_1}^{2^{N-n_1+1}(k_1+1) - 1} \cdots \sum_{\ell_p =
      2^{N-n_p+1} k_p}^{2^{N-n_p+1}(k_p+1) - 1} \f{\pa^p X^N_T}{\pa
      \Delta^N_{\ell_1} \cdots \pa \Delta^N_{\ell_p} W} \f{\pa
      \Delta^N_{\ell_1} W}{\pa Z_{n_1,k_1}} \cdots \f{\pa
      \Delta^N_{\ell_p}W}{\pa Z_{n_p,k_p}}.
  \end{equation*}
  By a similar argument as in~\eqref{eq:d2XdWdW} we see that
  \begin{equation*}
    \f{\pa^p X^N_T}{\pa \Delta^N_{\ell_1} \cdots \pa \Delta^N_{\ell_p} W} = \mathcal{O}(1).
  \end{equation*}
  By~\eqref{eq:dWdZ} we see that each summand in the above sum is of order
  $\prod_{j=1}^p 2^{-(N-n_j/2)}$. The number of summands in total is
  $\prod_{j=1}^p 2^{N-n_j+1}$. Therefore, we obtain the desired result. 
\end{proof}

\begin{theorem}
  \label{thr:smoothness}
  For any $p \in \N$ and indices $n_1, \ldots, n_p$ and $k_1, \ldots, k_p$
  (satisfying $0 \le k_j < 2^{n_j}$) we have (with constants independent from
  $n_j, k_j$)
  \begin{equation*}
    \f{\pa^p H^N}{\pa z_{n_1,k_1} \cdots \pa z_{n_p,k_p}}(Z^N) = 
    \mathcal{O}\left( 2^{-\sum_{j=1}^p n_j/2} \right).
  \end{equation*}
  The result also holds (mutatis mutandis) if one or several $z_{n_j,k_j}$ are
  replaced by $y = z_{-1}$ (with $n_j$ set to $0$). In particular, $H^N$ is a
  smooth function.
\end{theorem}

\begin{remark}
  \label{rem:analyticity}
  We actually expect that $H^N$ is analytic, but a formal proof seems
  difficult. In particular, note that our proof below relies on successively
  applying the above trick for enabling integration by parts: divide by
  $\f{\pa X^N_T}{\pa y}$ and then integrate by parts. This means that the
  number of terms (denoted by $\blacksquare$ below) increases fast as $p$
  increases by the product rule of differentiation. Hence, the constant in
  fron of the $\mathcal{O}\left( 2^{-\sum_{j=1}^p n_j/2} \right)$ term will
  depend on $p$ and increase in $p$. In that sense,
  Theorem~\ref{thr:smoothness} needs to be understood as an assertion about
  the anisotropy in the variables $z_{n,k}$ rather than a statement about the
  behaviour of higher and higher derivatives of $H^N$. In fact, one can see
  that in our proof the number of summands increases as $p!$ in
  $p$. Therefore, the statement of the theorem does not already imply
  analyticity. Of course, this problem is an artifact of our construction, and
  there is no reason to assume such a behaviour in general.
\end{remark}

\begin{proof}[Sketch of a proof of Theorem~\ref{thr:smoothness}]
  We apply integration by parts $p$ times as in the proof of
  Proposition~\ref{prop:first-derivatives}, which shows that we can again
  replace the mollified payoff function $g_\delta$ by the true, non-smooth one
  $g$. Moreover, from the procedure we obtain a formula of the form
  \begin{equation*}
    \f{\pa^p H^N}{\pa z_{n_1,k_1} \cdots \pa z_{n_p,k_p}} (z^N) = \int_{\R}
    g\left( X^N_T(y, z^N) \right) \blacksquare \f{1}{\sqrt{2\pi}} e^{-\f{y^2}{2}} dy,
  \end{equation*}
  where $\blacksquare$ represents a long sum of products of various
  terms. However, it is quite easy to notice the following structure: ignoring
  derivatives w.r.t.~$y$, each summand contains all derivatives
  w.r.t.~$z_{n_1,k_1}, \ldots, z_{n_p,k_p}$ exactly once. (Generally speaking,
  each summand will be a product of derivatives of $X^N_T$ w.r.t.~some
  $z_{n_j,k_j}$s, possibly with other terms such as polynomials in $y$ and
  derivatives w.r.t.~$y$ included.) As all other terms are assumed to be of
  order $\mathcal{O}(1)$ by Assumptions~\ref{ass:boundedness-derivative}
  and~\ref{ass:boundedness-inverse}, this implies the claimed result by
  Lemma~\ref{lem:d2XdZ2}. 
\end{proof}