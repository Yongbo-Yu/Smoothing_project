Many option pricing problems  require the computation of multivariate integrals. The dimension of these integrals
is determined by the number of independent stochastic factors (e.g. the number of time steps in the time discretization or the number of assets under consideration).  The high dimension of these integrals can be treated with dimension-adaptive quadrature methods to have the desired convergence behavior.

Unfortunately, in many cases, the  integrand contains either kinks and jumps. In fact, an option is normally considered worthless if the value falls below a predetermined strike price.  A kink  (discontinuity in the gradients) is present when the payoff function is  continuous, while a jump (discontinuity in the function)  exists when the payoff corresponds to a binary or other digital options. The existence of kinks or jumps in the integrand  heavily degrades
the performance of quadrature formulas.  In this work, we are interested in solving this problem  by using adaptive  sparse grids (SG) methods coupled with suitable transformations. The main idea is to find lines or areas of discontinuity and to employ suitable transformations of the integration domain. Then  by a pre-integration (smoothing) step with respect to the dimension containing the kink/jump,  we end up with integrating  only over the smooth parts of the integrand and the fast convergence of the sparse grid method can be regained.

One can ignore the kinks and jumps, and apply directly a method for integration over $\rset^d$.  Despite the  significant progress in SG methods \cite{bungartz2004sparse} for high dimensional integration  of  smooth integrands, few works have been done to deal with  cases involving integrands with kinks or jumps due to the decreasing performance of SG methods in the presence of kinks and jumps. 

Some works \cite{griebel2013smoothing,bayersmoothing, griebel2017note,griewank2017high,xiao2018conditional} adressed similar kind of problems, characterized by the presence of kinks and jumps,  but with much more emphasis on Quasi Monte Carlo (QMC). In \cite{griebel2013smoothing, griebel2017note,griewank2017high}, an  analysis of the performance of  Quasi Monte Carlo (QMC) and SG methods has been conducted, in the presence of kinks and jumps.  In \cite{griebel2013smoothing,griebel2017note}, the authors studied the terms of the ANOVA decomposition of functions with kinks defined on $d$-dimensional Euclidean space $\rset^d$, and showed   that under some assumptions all but the the highest order ANOVA term  of the $2^d$ ANOVA terms can be smooth for the case of an arithmetic Asian option with the Brownian bridge construction. Furthermore, \cite{griewank2017high} extended the work in \cite{griebel2013smoothing,griebel2017note} from kinks
to jumps for  the case of an arithmetic average digital Asian option with the principal component analysis (PCA). The main findings in \cite{griebel2013smoothing,griebel2017note} was obtained  for an  integrand  of the form $f(\mathbf{x}) = \max(\phi(\mathbf{x}), 0)$ with $\phi$ being smooth. In fact, by assuming  i) the $d$-dimensional function $\phi$ has a positive partial derivative with respect to $x_j$ for some $j \in \{1,\dots,d\}$, ii) certain growth conditions at infinity are satisfied, the authors showed that the ANOVA terms of $f$ that do not depend on the variable $x_j$ are smooth.   We note that \cite{griebel2013smoothing,griebel2017note,griewank2017high} focus  more on  theoretical aspects of applying QMC in such a setting. On the other hand, we focus more on  specific practical problems, where we add the adaptivity paradigm to the picture.

A recent work \cite{xiao2018conditional} adresses similar kind of problems using QMC. Being very much related to \cite{bayersmoothing}, the authors i) assume that the conditional expectation can be computed explicitly, by imposing very strong assumptions. ii) Secondly, they  use  PCA on the gradients to reduce the effective dimension. In our work, we do not make such strong assumptions, which is why we need numerical methods, more precisely root finding and the quadrature in the first direction.



%\subsection{Notation}
%In the following, we clarify some notations that we will be using in this paper:
%\begin{itemize}
%	\item Given $\mathbf{x} \in  \rset^N$, $\mid \mathbf{x} \mid_0$  denotes the number of non-zero components of $\mathbf{x}$.
%	\item $\mathcal{L}_+$ denotes the set of sequences with positive components with only finitely many elements larger than $1$, \ie,  $\mathcal{L}_+=\{\boldsymbol{\beta}\in \nset_+^\nset: \mid \boldsymbol{\beta}-1\mid_0<\infty  \}$.
%\end{itemize}