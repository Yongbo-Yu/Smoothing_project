\documentclass[11pt]{article}

\usepackage{smoothing_paper}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%chiheb commands

\newcommand{\ie}{\emph{i.e.}}
\newcommand{\eg}{\emph{e.g.}}
\newcommand{\cf}{\emph{cf.}}
\newcommand{\prob}[1]{\mathrm{P}\left(#1\right)}
\newcommand{\expt}[1]{\mathrm{E}\left[#1\right]}
\newcommand{\expth}[1]{\hat{\mathrm{E}}\left[#1\right]}



\newcommand{\rset}{\mathbb{R}}
\newcommand{\nset}{\mathbb{N}}
\newcommand{\zset}{\mathbb{Z}}



\newcommand{\PERIOD}{.}
\newcommand{\COMMA}{,}
\newcommand{\BIGSPACE}{\,\,\,\,\,\,\,}



\newcommand{\Ordo}[1]{{\mathcal{O}}\left(#1\right)}
\newcommand{\ordo}[1]{{o}\left(#1\right)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% DO WE RELLY NEED THE FOLLOWING??

%%  new margin
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{plain}                                                      %%
%%%%%%%%%% EXACT 1in MARGINS %%%%%%%                                   %%
\setlength{\textwidth}{6.5in}     %%                                   %%
\setlength{\oddsidemargin}{0in}   %%   
\setlength{\evensidemargin}{0in}  %%        
\setlength{\textheight}{8.5in}    %%       
\setlength{\topmargin}{-0.2in}    %%   
\setlength{\headheight}{0in}      %%    
\setlength{\headsep}{0in}         %%                   
\setlength{\footskip}{.5in}       %%                       
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%                                   %%
\newcommand{\required}[1]{\section*{\hfil #1\hfil}}                    %%
\renewcommand{\refname}{\hfil References Cited\hfil}                   %%

\def\SMALLSKIP{\smallskip}
\def\MEDSKIP{\medskip}
\def\BIGSKIP{\bigskip}

%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Efficient option pricing for Rough Bergomi model} 
    \date{ }

\begin{document}
\maketitle

\section{Introduction}
\subsection{The goal and outline of the project}
The main goal of the project is to design a fast option pricer, based on multi-index stochastic collocation (MISC) as \cite{haji2016multi}, for options whose dynamics follow rBergomi model as in \cite{bayer2016pricing}. We may later investigate QMC.

\subsection{Review of literature}
Extending the Black-Scholes model, in which volatility is assumed to be constant, to the case where the volatility is stochastic has proved to be successful in explaining certain phenomena observed in option price data, in particular the implied volatility smile. The main drawback of such stochastic volatility models, however, is that they are unable to capture the true steepness of the implied volatility smile close to maturity. 
While choosing to add jumps to stock price models, for example modelling the stock price process as an exponential L\'evy process, does indeed produce steeper implied volatility smiles, the issue of the presence of jumps in stock price processes remains controversial\cite{bajgrowicz2015jumps,christensen2014fact}.

As an alternative to diffusive stochastic volatility models, rough stochastic volatility has emerged as a new paradigm in quantitative finance,  motivated by the statistical analysis of realised volatility by Gatheral, Jaisson and Rosenbaum \cite{gatheral2014volatility} and the theoretical results on implied volatility by Fukasawa \cite{fukasawa2011asymptotic}. In these models, the trajectories of volatility are less regular than those of the standard Brownian motion. As shown in \cite{gatheral2014volatility,bayer2016pricing}, these models are a family of (continuous-path) stochastic volatility models where the driving noise of the volatility process has H\"older regularity lower than Brownian motion, typically achieved by modeling the fundamental noise innovations of the volatility process as a fractional Brownian motion with Hurst exponent (and hence H\"older regularity)$0<H<1/2$.   A major advantage of such rough volatility models is the fact that they allow to  explain crucial phenomena  observed in  financial markets both from a statistical \cite{gatheral2014volatility,bennedsen2016decoupling} and
an option-pricing point of view \cite{bayer2016pricing}. For instance, it was observed empirically  that in equity markets   that as time to maturity becomes small the empirical implied volatility skew follows a power law with negative exponent, and thus becomes arbitrarily large near zero.  While standard stochastic volatility models with continuous paths struggle to capture this phenomenon, predicting instead a constant at-the-money implied volatility behaviour on he short end  \cite{gatheral2011volatility}, 
 fractional stochastic volatility models (and more specifically so-called rough volatility models) constitute  alternative  models  that  fit empirical implied volatilities for short dated options. Consequently, they have become the go-to models capable of reproducing stylised facts of financial markets.



 Rough volatility models are based on fractional Brownian motion (fBM), which  is a centred Gaussian process, whose covariance structure depends on the Hurst parameter $H \in (0, 1)$. If $H \in(0,1/2)$, then the fractional Brownian motion has negatively correlated increments and "rough" sample paths, and if $H \in (1/2,1)$ then it has positively correlated increments and "smooth" sample paths, when compared with a standard Brownian motion, which is recovered by taking $H=1/2$. Gatheral, Jaisson, and Rosenbaum \cite{gatheral2014volatility} justify  empirically  the benefits of such models; in particular, they argue that log-volatility in practice behaves essentially as fBM with the Hurst exponent $H \approx 0.1$ at any reasonable time scale (see also  \cite{gatheral2014volatility_2}). This finding is confirmed  by Bennedsen, Lunde and Pakkanen \cite{bennedsen2016decoupling}, who study over a thousand individual US equities and find that the Hurst parameter $H$ lies in $(0,1/2)$ for each equity.




 The rough Bergomi (rBergomi) model is one of the recent rough volatility models, developed by Bayer, Friz and Gatheral \cite{bayer2016pricing},  that is consistent with the stylised fact of implied volatility surfaces being essentially time-invariant, and are able to capture the term structure of skew observed in equity markets. In \cite{bayer2016pricing}, the authors constructed the rBergomi model by  moving from  physical to pricing measure and simulated prices under that model to fit well the implied volatility surface in the case of the S\&P $500$ index with
 few parameters-just three!. They claim that the fractional model generates strong skews or "smiles" in the implied volatility even for very short time to maturity so that this modeling provides an
 alternative to using jumps to model such an effect. In \cite{bayer2016pricing} the model is so named because of its relationship with the Bergomi variance curve model \cite{bergomi2005smile}, and may be seen as a non-Markovian
generalisation of the latter.


%From a practical perspective  a natural issue  appears: What does the mantra of rough volatility mean for a trader with a view to hedging his positions?


 Due to the non-Markovian nature of the fractional driver, pricing  and hedging under rough volatility constitute a significant challenge. In fact, the popularity of asset pricing models hinges on the availability of efficient numerical pricing methods. In the case of diffusions, these include Monte Carlo (MC) estimators, PDE discretization schemes, asymptotic expansions and transform
methods. With fractional Brownian motion being the prime example of a process beyond the semi-martingale framework, most currently prevalent option pricing methods -particularly the ones assuming semimartingality or Markovianity - may not easily carry over to the rough setting. In fact,  due to the lack of Markovianity or affine structure, conventional analytical pricing methods  do not apply. At the moment, the only known method for pricing  options under such models is MC simulation. In particular, recent advances in simulation methods for the rough Bergomi model have been achieved in \cite{bayer2016pricing,bayer2017regularity,mccrickerd2017turbocharging,bennedsen2017hybrid,jacquier2018vix}. For isntance, in \cite{mccrickerd2017turbocharging}, the authors employ a novel composition of variance reduction methods, immediately applicable to any conditionally log-normal  stochastic volatility model. They got a substatantial computation gain in the pricing  over the exisiting MC methods. On the other hand,  more analytical results of option pricing and implied volatility under this model has been done in \cite{jacquier2017pathwise,bayer2017short,forde2017asymptotics}. For isntance, in \cite{jacquier2017pathwise},
they  characterise the small-time behaviour of implied volatility using large deviations theory and  related results, concerning the small-time near-the-money skew, have been  obtained by Bayer, Friz, Gulisashvili, Horvath and Stemper \cite{bayer2017short}. However, we should point out that pricing and model calibration under rough volatility models still remains time consuming.


In this paper, we suggest to design  a fast option pricer, based on multi-index stochastic collocation (MISC) as in \cite{haji2016multi}, for options whose dynamics follow rBergomi model as in \cite{bayer2016pricing}. We may later investigate QMC.



%Following \cite{gatheral2014volatility}, Bayer, Friz and Gatheral \cite{bayer2016pricing} propose the so-called rough Bergomi model, which they then use to price options on integrated volatility and on the underlying itself. The advantage of their model is that it captures the "rough" behaviour of log volatility, in accordance with \cite{bennedsen2016decoupling,gatheral2014volatility}, as well
%as fits observed implied volatility smiles better than traditional Markovian stochastic volatility models, most notably in the close-to-maturity case.

%It is a well-documented fact on Equity markets (see for instance  Chapter 5 of \cite{gatheral2011volatility}) that standard (It\^o) stochastic models with continuous paths are not able to capture the observed steepness of the left wing of the smile when the maturity becomes small. To remedy this, several authors have
%suggested the addition of jumps, either in the form of an independent L\'evy process or within the more general
%framework of affine diffusions. Jumps (in the stock price dynamics) imply an explosive behaviour for the small maturity
%smile and are better able to capture the observed steepness of the small-maturity implied volatility smile. In particular, Tankov \cite{tankov2011pricing} showed that, for exponential L\'evy models with L´evy measure supported on the whole real line, the squared implied volatility smile explodes as $\sigma^2_\tau(k)\sim −k^2/(2\tau\log\tau)$, as the maturity tends to zero, where $k$ represents the log-moneyness. Such a small-maturity behaviour of the smile is not only captured by jump-based models, but rough volatility (non-Markovian) models, where the stochastic volatility
%component is driven by a fractional Brownian motion, are in fact also able to reflect this property of the data.
 
% Indeed both regimes have been identified from the empirical perspective. We refer to for instance \cite{gatheral2014volatility}
% for observations of rough volatility, while in \cite{chronopoulou2012estimation}  of volatility with long-range correlation properties are reported. Long-range volatility
% situations have been reported for currencies in \cite{walther2017true} and  for commodities
% in \cite{charfeddine2014true}, while analysis of
% electricity markets data typically gives $H<1/2$ as in \cite{rypdal2013modeling,bennedsen2015rough}. We believe that both the rough and the long range cases are important and can be observed depending on the specific market and regime.

% In a series of papers several authors \cite{bayer2017short,forde2017asymptotics,jacquier2017pathwise}  have indeed proved that, when the Hurst index of the fractional Brownian motion lies within $(0,1/2)$, then the implied volatility explodes at a rate of $\tau^{H-1/2}$ as the maturity tends to zero.
\subsection{Background on Gaussian and fBM processes}
A zero-mean real-valued Gaussian process $(Z_t)_{t\ge0}$ is a stochastic process such that on any finite subset $\{t_1,\dots t_n\} \subset \rset, (Z_{t_1},\dots, Z_{t_n})$ has a
multivariate normal distribution with mean zero. The law of a Gaussian process is entirely determined by the covariance function $K(s, t)= \expt{Z_t Z_s}$ and $Z$ induces a Gaussian probability
measure on $(E, \mathcal{B}(E))$, where $E$ denotes the Banach space $C_0([0,1])$ with the usual sup norm topology (see, e.g., section 3.1.1 of  \cite{carmona2007interest} for details).



Fractional Brownian motion (fBM) is a natural generalization of standard Brownian motion which preserves the properties of stationary increments, self-similarity, and Gaussian finite-dimensional distributions, but it has a more complex dependence structure. In this section, we recall the definition and summarize the basic properties of fBM.

A zero-mean Gaussian process $B^H_t$ is called standard fractional Brownian motion (fBM) with Hurst parameter $H \in(0,1)$ if it has covariance function

\begin{align}\label{eq:fbm_cov}
R_H=\expt{B_t^H B_s^H}-\expt{B_t^H}\expt{B_s^H}=\frac{1}{2} \left(\abs{t}^{2H}+\abs{s}^{2H}-\abs{t-s}^{2H}\right).	
\end{align}



In order to specify the distribution of a Gaussian process, it is enough to specify its mean and its covariance function; therefore, for each $H$, the law of $B^H$ is uniquely determined by $R_H(s, t)$. However, this definition by itself does not guarantee the existence of fBM; to show that fBM exists, one needs to verify that the covariance function is nonnegative definite.

We now recall some fundamental properties of fBM (see also Figure \ref{fig:fBM}):

\begin{itemize}
	\item fBM is continuous a.s. and H-self-similar (H-ss), i.e., for $a>0, (B_{at})_{t \ge 0}  \overset{(d)}{=} a^H (B_t)_{t \ge 0}$ where $ \overset{(d)}{=}$ means both processes have the same finite-dimensional distributions. For $H \neq 1/2$, $B^H$ does not have independent increments; for $H=1/2, B^H_t$ is the standard Brownian motion. 
	\item From \eqref{eq:fbm_cov}, we see that 
	\begin{equation*}
	\expt{(B_t^H-B_s^H)^2}=\abs{t-s}^{2H},
	\end{equation*}
so $B_t^H-B_s^H \sim \mathcal{N}(0,\abs{t-s}^{2H})$; thus $B^H$ has stationary increments.
\item If we set $X_n=B^H_n-B^H_{n-1}$, then $X_n$ is a  discrete-time Gaussian process with covariance function

\begin{align*}
\rho_n&=\expt{X_{k+n} X_n}=\expt{\left(B_{k+n}^H -B^H_{k+n-1}\right)\left(B_{k}^H -B^H_{k-1}\right)}\\
&\sim H (2H-1) n^{2H-2}\quad (n \rightarrow \infty),
\end{align*}
and thus (by convexity of the function $g(n) = n^{2H})$, we see that two increments the form $B_k-B_{k-1}$ and $B_{k+n}-B_{k+n-1}$ are positively correlated if $H  \in (1/2,1)$ and negatively correlated if $H \in (0,1/2)$. Thus $B^H$ is persistent (i.e., it is more likely to keep a trend than to break it) when $H>1/2$, the relatively stronger positive correlation for the consecutive increments of the associated fBm process with increasing $H$ values gives a relatively smoother process whose correlations decay relatively slowly.On the other hand, it is antipersistent when $H<1/2$ (i.e., if $B^H$ was increasing in the past, it is more likely to decrease in the future, and vice versa). The enhanced negative correlation with smaller Hurst exponent gives a relatively rougher process.

\item If $H \in (1/2,1)$, we can show that $\sum_{n=1}^\infty \rho_n= \infty$, which means that the process exhibits long-range dependence, but if $H \in(0, 1/2)$, then  $\sum_{n=1}^\infty \rho_n< \infty$.

\item Using that $\expt{(B^H_t- B^H_s)^2} = (t-s)^{2H}$, we can show that sample paths of $B^H$ are $\alpha$-H\:older continuous for all $\alpha \in (0,H)$.
\item fBM is the only self-similar Gaussian process with stationary increments (see, e.g., \cite{marquardt2006fractional}), and for $H\neq 1/2$, $B^H_t$ is neither a Markov process nor a semimartingale (see, e.g., \cite{nualart2006malliavin}).
\end{itemize}



For more details regarding the fBm processes we refer to \cite{biagini2008stochastic,coutin07introduction,mandelbrot1968fractional}.

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.45\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/fbm_H_0_9}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.45\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/fbm_H_0_3}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Monte Carlo simulation of fBM for $H = 0.9$ (left) and $H = 0.3$ (right).}
	\label{fig:fBM}
\end{figure}



\section{Problem setting}
\subsection{The rBergomi model}\label{sec:The rBergomi model}

We use  the rBergomi model for the price process $S_t$ as defined in  \cite{bayer2016pricing}, normalized to $r=0$, which is defined by

\begin{align}\label{eq:rBergomi_model1}
	dS_t = \sqrt{v_t(\tilde{W}^H)} S_t dZ_t,\\
	v_t = \xi_0(t) \exp\left( \eta \tilde{W}_t^H - \frac{1}{2} \eta^2 t^{2H} \right),
\end{align}
where for $0 < H < 1$ and  $\eta>0$.  We have $\tilde{W}^H $ is a certain Volterra process (Riemann-Liouville
process),  defined by
\begin{align}\label{eq:Volterra process}
	\tilde{W}_t^H = \int_0^t K^H(t,s) dW_s^1, \quad t \ge 0
\end{align}
where the kernel $K^H : \rset_+ \times \rset_+ \rightarrow \rset_+$ reads
\begin{align}
 \quad K^H(t,s) = \sqrt{2H} (t-s)^{H - 1/2},\quad \forall \: 0 \le s \le t.
\end{align}

We note that the map $s \rightarrow K^H(s,t)$ belongs to $L^2$, so
that the stochastic integral \eqref{eq:Volterra process} is well defined.

$W^1, Z$ denote two \emph{correlated} standard Brownian motions with correlation $\rho \in [-1,1]$, so that
\begin{align}
	Z:=\rho	W^1+ \bar{\rho}W^\perp \equiv \rho W^1+\sqrt{1-\rho^2} W^\perp,
\end{align}
where $(W^1,W^\perp)$ are two independent standard Brownian motions,
Therefore, Eq \ref{eq:rBergomi_model1} can be written as 

\begin{align}\label{eq:rBergomi_model}
	S_t&= S_0  \operatorname{exp}\left( \int_{0}^{t} \sqrt{v(s)} dZ(s)- \frac{1}{2} \int_{0}^{t} v(s) ds   \right),\quad S_0>0 \nonumber\\
	v(u)&=\xi_0(u) \operatorname{exp}\left( \eta \tilde{W}_u^H- \frac{\eta^2}{2} u^H \right), \quad \xi_0>0
\end{align}


The filtration $(\mathcal{F}_t)_{t\ge 0}$ can here be taken as the one generated by the two-dimensional Brownian motion $(W^1,W^\perp)$ under the risk neutral measure $\mathbb{Q}$, resulting in  a filtered probability space $(\Omega,\mathcal{F}; \mathcal{F}_t,\mathbb{Q})$. The stock price process $S$ is clearly then a local
$(\mathcal{F}_t)_{t\ge 0}$-martingale and a supermartingale, therefore integrable.  We shall henceforth use the notation $\expt{.} = E^{\mathbb{Q}}\left[. \mid \mathcal{F}_0\right]$ unless we state otherwise.

We refer to $v_u$ as the variance process, where $\xi_0(u) = \expt{v_u} \in \mathcal{F}_0$ a.s. the forward variance curve. $\tilde{W}^H $ is a centered, locally $(H-\epsilon)$- H\" \o lder continuous, Gaussian process with $\var{[\tilde{W}^H_t]} = t^{2H}$.




We note that the model parameters $(\eta,\rho,H)$ may have an
 intuitive interpretation of their influence over implied volatilities. In fact,   $\eta$ might seen as  smile, $\rho$ as skew, $H-1/2$ as the explosion(smile and skew).

\subsection{Option pricing under rBergomi model}\label{sec:Option pricing under rBergomi model}

Assuming $S_0 = 1$, and using the conditioning argument on the $\sigma$-algebra generated by $W^1$ (argument first used by \cite{romano1997contingent} in the context of Markovian SV
models), we can  show that the call price is given by

\begin{align}\label{BS_formula_rbergomi}
	C_{RB}\left( T, K \right) &= E\left[ \left(S_T - K \right)^+ \right]  \nonumber\\
	&=\expt{\expt{(S_T-K)^+ \mid \sigma(W^1(t) ,t \le T)}}\nonumber \\
	&=E\left[C_{BS}\left( S_0 = \operatorname{exp}\left(\rho \int_0^T \sqrt{v_t} dW_t^1 - \frac{1}{2}
	\rho^2 \int_0^T v_t dt\right),\ K = K, \ T = 1, \ \sigma^2 = (1-\rho^2)
	\int_0^T v_t dt \right) \right],
\end{align}
where $C_{BS}$ denotes the Black-Scholes price.

In fact, if we use the orthogonal decomposition of $S_t$ into $S_{t}^1$ and $S_{t}^2$, where

\begin{align}
	S_t^1:=\mathcal{E}\{ \rho \int_{0}^{t}  \sqrt{v_s} dW_s^1\}, \: S_t^2:= \mathcal{E}\{ \sqrt{1-\rho^2} \int_{0}^{t}  \sqrt{v_s} dW_s^\perp  \}	,
\end{align}

where $\mathcal{E}()$ denotes the stochastic exponential, then, we obtain by conditional log-normality
\begin{align}
	\log S_t \mid \mathcal{F}_t^1 \sim \mathcal{N}\left( \log S_t^1-\frac{1}{2} (1-\rho^2) \int_{0}^{t} v_s ds , (1-\rho^2) \int_{0}^{t} v_s ds \right),
\end{align} 

where $\mathcal{F}_t^1= \sigma\{ W_s^1: s\le t\}$. Therefore, we obtain \eqref{BS_formula_rbergomi}.



We insist that the smoothing trick, based on conditionning, performed in Eq \eqref{BS_formula_rbergomi} enable us to get a smooth term inside the expectation. Therefore, applying sparse quadrature techniques becomes an adequate option for computing the call price as we shall see later.



\subsection{Simulation of the rBergomi model}\label{sec:Simulation of the rBergomi model}

The main challenge is the computation of $S=\int_{0}^{T} \sqrt{v_t} dW_t^1$ and $V=\int_{0}^{T} v_t dt$. As was mentioned in \cite{bayer2017regularity}, we may try to
avoid any sampling related to $W^2$ by   a brute-force approach that  consists in simulating a scalar Brownian motion $W^1$, followed by computing  $\tilde{W}^H= \int K dW^1$  by It\^o/Riemann Stieltjes approximations of $(S,V)$. However, this is not advisable given the singularity of the Volterra kernel $K(s,t)$ at the diagonal $s = t$.
 Therefore,  one needs to jointly simulate the two-dimensional Gaussian process $(W_t^1, \tilde{W}^H_t: 0 \le t \le T)$, resulting in $W^1_{t_1},\dots, W_{t_N}$ and $\tilde{W}^H_{t_1},\dots, \tilde{W}^H_{t_N}$ along a given grid $t_1 <\dots < t_N$. There are essentially three possible ways to achieve this:
 \begin{enumerate}
 	\item Euler discretization of the integral defining $\tilde{W}^H$ together with classical simulation of increments of $W^1$. This is horribly inefficient because the integral is singular and adaptivity probably does not help, as the singularity moves with time. For this 	method, we need an $N$-dimensional random Gaussian input vector to produce one (approximate, inaccurate) sample of $W^1_{t_1},\dots, W^1_{t_N}, \tilde{W}^H_{t_1},\dots, \tilde{W}_{t_N}$.
 	
 	\item Given that $W^1_{t_1},\dots, W^1_{t_N}, \tilde{W}^H_{t_1},\dots, \tilde{W}_{t_N}$ together forms a ($2N$)-dimensional Gaussian random vector with computable covariance matrix. We can use Cholesky decomposition of the covariance matrix to produce exact samples of $W^1_{t_1},\dots, W^1_{t_N}, \tilde{W}^H_{t_1},\dots, \tilde{W}_{t_N}$, but unlike the first way, we need $2N$-dimensional Gaussian random vectors as
 	input. This method is exact but slow (See  \cite{bayer2016pricing} and Section $4$ in \cite{bayer2017short} ). The simulation  requires $\Ordo{N^3}$. flops. 
 	
 	\item  The hybrid scheme of \cite{bennedsen2017hybrid} uses a different approach, which is essentially based on  Euler discretization as the first way but crucially improved by moment
 	matching for the singular term in the left point rule. It is also
 	inexact in the sense that samples produced here do not exactly have the distribution of $W^1_{t_1},\dots, W^1_{t_N}, \tilde{W}^H_{t_1},\dots, \tilde{W}_{t_N}$, however they are much more accurate then samples produced from method $1)$, but much faster than method $2)$. As in method $2)$, in this case we need a $2N$-dimensional Gaussian random input vector to produce one
 	sample of $W^1_{t_1},\dots, W^1_{t_N}, \tilde{W}^H_{t_1},\dots, \tilde{W}_{t_N}$.
 \end{enumerate}
In this project, we adopt the last approach for the simulation of the rBergomi model. We utilise the first order variant $(\kappa=1) $ of the hybrid scheme \cite{bennedsen2017hybrid}, which is based on the approximation

\begin{equation}\label{eq:Hybrid_scheme}
\tilde{W}^H_{\frac{i}{N}} \approx \bar{W}_{\frac{i}{N}}:= \sqrt{2H} \left(\int_{\frac{i-1}{N}}^{\frac{i}{N}} \left(\frac{i}{N} -s\right)^{H-\frac{1}{2}} dW_u^1+\sum_{k=2}^{i} \left(\frac{b_k}{N}\right)^{H-\frac{1}{2}} \left(W_{\frac{i-(k-1)}{N}}^1-W_{\frac{i-k}{N}}^1\right)\right)
\end{equation}
where $N$ is the number of time steps and 
$$ b_k:=\left(\frac{k^{H+\frac{1}{2}}-(k-1)^{H+\frac{1}{2} }}{H+\frac{1}{2}}\right)^{\frac{1}{H-\frac{1}{2}}}$$

Employing the fast Fourier transform to evaluate the sum in \eqref{eq:Hybrid_scheme}, which is a discrete convolution, a skeleton $\bar{W}_0^{H},\bar{W}_1^{H},\dots,\bar{W}_{\frac{[Nt]}{N}}^{H}$ can be generated in $\Ordo{N \log N}$ foating point operations.


The variates $\bar{W}_0^{H},\bar{W}_1^{H},\dots,\bar{W}_{\frac{[Nt]}{N}}^{H}$ can be generated by sampling $[nt]$ iid draws from a $\kappa+1$-dimensional Gaussian
distribution and computing a discrete convolution. We call these pairs  of Gaussian random variables from now on as $(W^1,W^2)$.
%
%In this sense, I (sloppily) claimed that the hybrid scheme require 2
%Brownian motions. This is strictly speaking incorrect. You need,
%however, a (2N)-dimensional Gaussian input vector in order to get one
%N-dimensional sample W_{t_1}, ..., W_{t_N} of the driving Brownian
%motion and one N-dimensional sample of the associated fractional
%Brownian motion, which have (approximately) the correct joint
%distribution.



\section{Details our approach and error bounds}\label{sec:Details our approach and error bounds}



Our approach of computing the expectation in \eqref{BS_formula_rbergomi} is based on multi-index stochastic collocation (MISC), suggested in \cite{haji2016multi}. We describe the general strategy for the multi-index construction in Section \ref{sec:Details of the MISC}. Recall that  there are two  $N$ dimensional Gaussian inputs for the used  hybrid  approach ($N$ is the number of time steps in  the time grid) , namely
\begin{itemize}
	\item $\{W^1\}_{i=1}^N$: The $N$ Gaussian random parameters that are defined in Section  \ref{sec:The rBergomi model}.
	\item $\{W^2\}_{i=1}^N$: An artificial introduced $N$ Gaussian random parameters that are used for left-rule points in the hybrid scheme, explained in Section  \ref{sec:Simulation of the rBergomi model}.
\end{itemize}

We have a natural error decomposition for the total error of computing the the expectation in \eqref{BS_formula_rbergomi}, namely, $\mathcal{E}$

\begin{equation}\label{eq:total_error}
\mathcal{E} \le \mathcal{E}_Q(TOL_{\text{MISC}},N) + \mathcal{E}_B(N),
\end{equation}
where  $\mathcal{E}_Q$ is the quadrature error, function of MISC tolerance $TOL_{\text{MISC}}$ and $N$ (the number of time steps)  and  $\mathcal{E}_B$  is the bias, function of $N$ (the number of time steps) or $\Delta_t=\frac{T}{N}$ (size of the time grid).




We note that sampling the Brownian motion can be constructed either sequentially using a standard random walk construction or hierarchically using Brownian bridge (BB) construction. To make an effective use of MISC, which is badly affected by isotropy, we use the BB construnction since it produces  dimensions with different importance for MISC (creates anisotropy), contrary to random walk procedure for which all the dimension of the stochastic space have equal importance (isotropic). We explain the BB construction in Section \ref{sec:Brwonian bridge construction}. This transformation plays a role of dimension reduction of the problem and as a consquence accelerating the MISC procedure by reducing the compotational cost.



Another way to reduce the dimension of the problem is by using Richardson extrapolation, explained in Section \ref{sec:Richardson extrapolation}. In fact, Richardson extrapolation acts on both the bias (by reducing it) and MISC procedure by redcing the number of needed time steps ,$N$, neeeded to achive a certain tolerance, resulting in a lower dimensional problem.


Motivated by some numerical observations regarding the behavior of the MISC solver with respect to the standard Gaussian hermite quadrature (See Section \ref{sec:Numerical tests}), We build a more robust MISC solver by incorporating a change of measure with respect to $W^1$ as described in Section \ref{sec:Gaussian Hermite Quadrature with importance sampling}.
 
We also discuss the  error bounds in Section \ref{sec: Discussion about error bounds}

\subsection{Details of the MISC}\label{sec:Details of the MISC}

We focus on solving the problem of  approximating the expected value of $\expt{f(y)}$ on a tensorization of quadrature formulae over the stochastic domain, $\Gamma$. Assuming that $f(y)$ is a continuous function (analytic) over $\Gamma$. A quadrature approach is very adequate.

Let us define $\beta \le 1$ be an integer positive value referred to as a "stochastic discretization level", and $m: \nset \rightarrow \nset$ be a strictly increasing function with $m(0)=0$ and $m(1)=1$, that we call a "level-to-nodes function". At level $\beta$, we consider a set of $m(\beta)$ distinct quadrature points in $(-\infty; \infty)$, $\mathcal{H}^{m(\beta)}=\{y^1_\beta,y^2_\beta,\dots,y_\beta^{m(\beta)}\} \subset [-\infty,\infty]$, and a set of quadrature weights, $\mathcal{W}^{m(\beta)}=\{\omega^1_\beta,\omega^2_\beta,\dots,\omega_\beta^{m(\beta)}\}$. We also let $C^0((-\infty,\infty))$ be the set of real-valued continuous functions over $(-\infty, \infty)$. We then define the quadrature operator as


\begin{equation}
Q(m(\beta)):C^0((-\infty,\infty)) \rightarrow \rset, \quad Q(m(\beta))[f]= \sum_{j=1}^{m(\beta)} f(y^j_\beta) \omega_\beta^j.
\end{equation}






In the multi-variate case $\Gamma$ is defined as a countable tensor
product of intervals. Therefore,  we define, for any definitely supported multi-index $\boldsymbol{\beta} \in \mathcal{L}_+$

$$Q^{m(\boldsymbol{\beta})}: \Gamma \rightarrow \rset,\quad  Q^{m(\boldsymbol{\beta})}= \bigotimes_{n \ge 1} Q^{m(\beta_n)} $$

where the $n$-th quadrature operator is understood to act only on the $n$-th variable of $f$. Practically, we obtain the value of $Q^{m(\boldsymbol{\beta})}[f]$  by considering the tensor grid $\mathcal{T}^{m(\boldsymbol{\beta})}= \times_{n \ge 1} \mathcal{H}^{m(\beta_n)}$ with cardinality $\#\mathcal{T}^{m(\boldsymbol{\beta})}=\prod_{n \ge 1} m (\beta_n)$ and computing

$$ Q^{\mathcal{T}^{m(\boldsymbol{\beta})}}[f]= \sum_{j=1}^{\#\mathcal{T}^{m(\boldsymbol{\beta})}} f(\hat{y}_j) \bar{\omega}_j$$
where $\hat{y}_j \in \mathcal{T}^{m(\boldsymbol{\beta})}$ amd $\bar{\omega}_j$ are (infinite) products of weights of the univariate quadrature rules. We Note that it is essential in this construction that $m(1)=1$ so that the cardinality of $\mathcal{T}^{m(\boldsymbol{\beta})}$ is finite for any $\boldsymbol{\beta} \in \mathcal{L}_+$ and $ \omega_{\beta_n}^1=1$ whenever $n = 1$, so that all weights, $\bar{\omega}_j$, are bounded.

We mention that the quadrature points are chosen to optimize the convergence properties of the quadrature error.  

A direct approximation $\expt{f} \approx Q^{m(\boldsymbol{\beta})}[f]$ is not an appropriate option  due to the well-known "curse of dimensionality" effect. We use multi-index stochastic collocation (MISC) as it was suggested  in \cite{haji2016multi}. MISC as a hierarchical adaptive quadrature strategy that uses  stochastic discretizations  and classic sparsification approach to obtain an effective approximation scheme for $\expt{f}$. 


In our setting, we are left with a $2N$- dimensional Gaussian random inputs, which are chosen independently, resulting in  $2N$ numerical parameters, which we use as the basis of the multi-index construction, reflecting the fact that $W^1_i$ and $W^2_j$ can vary independently of each other regardless of $i \neq j$ or $i = j$. For the sake
of concreteness, let $l \in \{1, \ldots, 2N\}$ and set
\begin{equation}
m_l \coloneqq
\begin{cases}
W^1_l, & 1 \le l \le N,\\
W^2_{l-N}, & N+1 \le l \le 2N.
\end{cases}
\end{equation}
For a multi-index $\ell = (l_i)_{i=1}^{2N} \in \mathbb{N}^{2N}$ we denote by
$Q^N_\ell \coloneqq Q^N(m_{\ell})$ the result of a discretized
integral, using $N$ time steps , with parameters $m_\ell \coloneqq (m_{l_i})_{i=1}^{2N}$. We further define the set of
differences $\Delta Q^N_\ell$ as follows: for a single index $1 \le i \le 2N$,
let
\begin{equation}
\Delta_i Q^N_\ell \coloneqq \left\{ 
\aligned 
Q^N(m_\ell) - Q^N(m_\ell') \text{ with } m_\ell' =
m_{\ell - e_i}, & \text{ if } \ell_i>0 \\
Q^N(m_\ell) & \text{ otherwise}
\endaligned
\right.
\end{equation}
where $e_i$ denotes the $i$th $2N$-dimensional unit vector. Then, $\Delta
Q^N_\ell$ is defined as
\begin{equation}
\Delta Q^N_\ell \coloneqq \left( \prod_{i=1}^{2N} \Delta_i \right) Q^N_\ell.
\end{equation}
For instance, when $N = 1$, then 
\begin{multline*}
	\Delta Q^1_\ell = \Delta_2 \Delta_1 Q^1_{(l_1, l_2)} = \Delta_2\left( Q^1_{(l_1,
		l_2)} - Q^1_{(l_1-1,l_2)} \right) = \Delta_2 Q^1_{(l_1,
		l_2)} - \Delta_2 Q^1_{(l_1-1,l_2)} 
	\\= Q^1_{(l_1, l_2)} - Q^1_{(l_1, l_2-1)} - Q^1_{(l_1-1, l_2)} + Q^1_{(l_1-1, l_2-1)}.
\end{multline*}

Note that $Q^N(m)$ converges to the biased option price (denoted by $Q^N(\infty)$ as
$m \to \infty$. Hence, we have the telescoping property
\begin{equation}
Q^N(\infty) = \sum_{l_1=0}^\infty \cdots \sum_{l_{2N} = 0}^\infty \Delta
Q^N_{(l_1, \ldots, l_{2N})} = \sum_{\ell \in \mathbb{N}^{2N}} \Delta Q^N_\ell,
\end{equation}
provided that $m_{l_1} \xrightarrow{l_1 \to \infty} \infty$, \ldots,
$m_{l_{2N}} \xrightarrow{l_{2N} \to \infty} \infty$. The telescoping property
is accompanied by a corresponding error factorization, i.e., the size of the
increment $\Delta Q^N_\ell$ can be bounded by a product of error terms depending
on $m_i$ and $m_{i+N}$.


We denote the computational work at level $\ell = (l_1, \ldots, l_{2N})$  for adding an increment $\Delta Q^N_{\ell}$
in the telescoping sum by  $W^N_\ell$, and   define the actual estimator for the quantity of interest
$Q^N(\infty)$: given a set of multi-indices $\mathcal{I} \subset
\mathbb{N}^{2N}$, let
\begin{equation*}
	Q^N(\mathcal{I}) \coloneqq \sum_{\ell \in \mathcal{I}} \Delta Q^N_\ell.
\end{equation*}
Then the error is given by
\begin{equation*}
	\abs{Q^N(\infty) - Q^N(\mathcal{I})} \le \sum_{\ell \in \mathbb{N}^{2N} \setminus
		\mathcal{I}} \abs{\Delta Q^N_\ell},
\end{equation*}


The construction of $\mathcal{I}$ will be done by profit thresholding, i.e.,
for a certain threshold value $T$, we add a multi-index $\ell$ to
$\mathcal{I}$ provided that
\begin{equation*}
	\log\left( \frac{\abs{\Delta Q^N_\ell}}{W^N_\ell} \right) \le T.
\end{equation*}
(Actually, we take the error estimate instead of the true error.)





\subsection{Gaussian Hermite Quadrature with importance sampling}\label{sec:Gaussian Hermite Quadrature with importance sampling}
Let us call the integrand that we feed to MISC by $I(W^1,W^2)$, then 

\begin{align}
	C_{RB}\left( T, K \right)=  \int_{\rset_+^{2N}} I(\mathbf{W}^1,\mathbf{W}^2)  \rho(\mathbf{W}^1) \rho(\mathbf{W}^2) d \mathbf{W}^1  d\mathbf{W}^2 \COMMA
\end{align}
where $N$ is the number of time steps. We can rewrite the previous expression as
\begin{align}\label{eq: importance sampling}
	C_{RB}\left( T, K \right)=  \int_{\rset_+^{2N}} \frac{I(\mathbf{W}^1,\mathbf{W}^2)\rho(\mathbf{W}^1)}{h(\mathbf{W}^1;\hat{\mathbf{W}}^1,\Psi)} {h(\mathbf{W}^1;\hat{\mathbf{W}}^1,\Psi)} \rho(\mathbf{W}^2) d \mathbf{W}^1  d\mathbf{W}^2 \COMMA
\end{align}
where $h(\mathbf{W}^1;\hat{\mathbf{W}}^1,\Psi)$ is a multivariate normal density with first and second order moments given by

\begin{align}\label{eq:Gaussian moments}
	\hat{\mathbf{W}}^1&=\operatorname{arg} \underset{\mathbf{W}^1 \in \rset^{N} }{\max}	[ \log I(\mathbf{W}^1;\mathbf{W}^2)] \\
	\Psi &=\left(- \frac{\partial^2[\log I(\mathbf{W}^1;\mathbf{W}^2)]}{\partial (\mathbf{W}^1)^{T} \mathbf{W}^1} \right)^{-1}_{\mathbf{W}^1=\hat{\mathbf{W}}^1}
\end{align}

Let us define $\tilde{\mathbf{W}}^1$ as uncorrelated varaibles and the Cholesky factorization of $\Psi$ is given by $\Psi=L L^{T}$, and $\bar{\mathbf{W}}^1=\sqrt{2} L \tilde{\mathbf{W}}^1+\hat{\mathbf{W}}^1$ then Eq \ref{eq: importance sampling} becomes 

\begin{align}
	C_{RB}\left( T, K \right)=2^{N/2}. \abs{L} \int_{\rset_+^{2N}} \left( I(\bar{\mathbf{W}}^1,\mathbf{W}^2)  \exp(-\frac{1}{2}(\bar{\mathbf{W}}^1)^T \bar{\mathbf{W}}^1) \exp(\frac{1}{2}\tilde{\mathbf{W}}^T \tilde{\mathbf{W}}) \right)   \rho(\tilde{\mathbf{W}}^1) \rho(\mathbf{W}^2) d \tilde{\mathbf{W}}^1 d\mathbf{W}^2 
\end{align}



%
\subsection{Brownian bridge construction}\label{sec:Brwonian bridge construction}

Let us denote $\{t_i\}_{i=0}^{N}$ the grid of time steps, then the BB construction \cite{glasserman2004monte} consists of the following: given a past value $B_{t_i}$ and a future value $B_{t_k}$, the value $B_{t_j}$ (with $t_i < t_j < t_k$) can be generated according to the formula:
\begin{equation}
B_{t_j}=(1-\rho) B_{t_i}+\rho B_{t_k}+ \sqrt{\rho (1-\rho)(k-i) \Delta t} z, \: z \sim \mathcal{N}(0,1) \COMMA
\end{equation}
where $\rho=\frac{j-i}{k-i}$.  In particular, if $N$ is a power of $2$, then given $B_0=0$, BB generates the Brownian motion at times $T, T/2,T/4,3T/4,\dots$ according
\begin{align}\label{eq:BB construction}
	B_T&=\sqrt{T}z_1\nonumber\\
	B_{T/2}&= \frac{1}{2}(B_{0}+B_{T})+\sqrt{T/4}z_2= \frac{\sqrt{T}}{2} z_1+\frac{\sqrt{T}}{2} z_2\nonumber\\
	B_{T/4}&=\frac{1}{2} (B_{0}+B_{T/2})+\sqrt{T/8}z_3= \frac{\sqrt{T}}{4} z_1+\frac{\sqrt{T}}{4} z_2+\sqrt{T/8}z_3\nonumber\\
	\vdots \nonumber\\
\end{align}
where $\{z_j\}_{j=1}^{N}$ are independent standard normal variables.  In BB construction given by \eqref{eq:BB construction}, the most important values that determine the large scale structure of Brownian motion are the first components of $\mathbf{z} = (z_1,\dots,z_N)$.



%In the simulation, we generate the stock prices using Brownian bridge (BB) in the following way: first generates the final value $W_d$ , then sample $W_{[d/2]}$ conditional on the values of $W_d$ and $W_0$, and proceed by progressively filling in intermediate values. Here, $[x]$ denotes the greatest integer less than or equal to $x$. In particular, if $d$ is a power of $2$, then
%BB generates the Brownian motion as
%\begin{align}\label{BB}
%	W_d&=\sqrt{T}Z_1\nonumber\\
%	W_{d/2}&= \frac{1}{2}(W_{0}+W_{d})+\sqrt{T/4}Z_2\nonumber\\
%	W_{d/4}&=\frac{1}{2} (W_{0}+W_{d/2})+\sqrt{T/8}Z_3\nonumber\\
%	\vdots \nonumber\\
%	W_{d-1}&= \frac{1}{2}(W_{d-2}+W_{d})+\sqrt{T/2d}Z_d,
%\end{align}
%where $Z_j$ are independent standard normal variables. 



\subsection{Richardson extrapolation}\label{sec:Richardson extrapolation}


We  recall that the Euler (often) scheme has weak order $1$ so that

\begin{align}\label{Euler_weak_error}
	\abs{\expt{f(\hat{X}_T^h)}-\expt{f(X_T)} }  \leq C h
\end{align}

for some constant $C$, all sufficiently small $h$ and suitably smooth $f$. It was shown that \ref{Euler_weak_error} can be improved to


\begin{align}\label{Euler_weak_error_strenghten}
	\expt{f(\hat{X}_T^h)}= \expt{f(X_T)} + c h +\Ordo{h^2} \COMMA
\end{align}


where $c$ depends on $f$. 

Applying \ref{Euler_weak_error_strenghten} with discretization step $2h$, we  obtain

\begin{align}\label{Euler_weak_error_strenghten_2h}
	\expt{f(\hat{X}_T^{2h})}= \expt{f(X_T)} + 2 c h +\Ordo{h^2} \COMMA
\end{align}

implying

\begin{align}\label{Richardson_extrapol}
	2 \expt{f(\hat{X}_T^{2h})}- \expt{f(\hat{X}_T^{h})} =\expt{f(X_T)} + \Ordo{h^2} \COMMA
\end{align}

For higher levels extrapolations, we use the following: Let us denote by $h_J=h_0.2^{-J}$ the grid sizes (where $h_0$ is the coarsest grid size), by $K$ the level of the Richardson extrapolation, and by $I(J,K)$ the approximation of $\expt{f^(\hat{X}_T^{h_J})}$ by terms up to level $K$ (leading to a weak error of order $K$), then we have

\begin{align}
I(J,K)=\frac{2^K\left[I(J,K-1)-I(J-1,K-1)\right]}{2^K-1} +\Ordo{h^{K+1}},\quad J=1,2,\dots, K=1,2,\dots
\end{align}




\subsection{Discussion about error bounds}\label{sec: Discussion about error bounds}


\textbf{TO-DO:} In this Section, we discuss each term in Eq \ref{eq:total_error} seperatly.
\subsubsection{Discussion about the Bias error}
\subsubsection{Discussion about the quadrature error}

\section{Numerical tests}\label{sec:Numerical tests}
In this Section, the default paramters values of the rBergomi model  (unless stated), defined in Section \ref{sec:The rBergomi model}, are: $S_0=1$, $\eta=1.9$, $\xi=0.235^2$, $\rho=-0.9$, $T=1$. 
\subsection{Motivation for the need of measure change}
In this Section, we motivate the need of measure change as a pre-processing step before applying the MISC solver.
\subsubsection{Integrand plotting wrt different random inputs } \label{sec:Integrand plotting wrt different random inputs}
In this section, we plot the integrand, given by the term inside the expectation in \eqref{BS_formula_rbergomi}(including the Gaussian density), wrt different random inputs $(W^1,W^2)$. This is important to check if we need a measure change and if needed for which variables. We show the results for  $H=0.07$ and for two scenarios of number of time steps $N \in \{2,4\}$ (similar plots are produced for $H=0.43$ in Appendices (\ref{Appendix:Integrand plotting wrt different random inputs N=2, H=0.43},\ref{Appendix:Integrand plotting wrt different random inputs: N=4, H=0.43}). We also show the two dimensional plots (See figures \ref{fig:Integrand_H_007_N_2_2D},\ref{fig:Integrand_H_007_N_4_2D_W_1_2_3},\ref{fig:Integrand_H_007_N_4_2D_W_1_3_3_4},\ref{fig:Integrand_H_007_N_4_2D_W_1_4_2_3}). As it seems from the plots, we  just need change of measure wrt to $W^1$ coordinates and we do not need a measure chnage for $W^2$ coordinates. 



\subsubsection*{N=2, H=0.07}


\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_2/H_007/Bergomi_integrand_K_1_H_007_W11_N_2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_2/H_007/Bergomi_integrand_K_1_H_007_W12_N_2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Plotting the integrand $I$ (in \eqref{BS_formula_rbergomi}) as a function of $W^1$ coordinates for $H=0.07$ and $N=2$.}
	\label{fig:Integrand_H_007_N_2_W_1}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_2/H_007/Bergomi_integrand_K_1_H_007_W21_N_2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_2/H_007/Bergomi_integrand_K_1_H_007_W22_N_2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Plotting the integrand $I$ (in \eqref{BS_formula_rbergomi}) as a function of $W^2$ coordinates for $H=0.07$ and $N=2$.}
	\label{fig:Integrand_H_007_N_2_W_2}
\end{figure}


\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/2D_plots/N_2/H_007/Bergomi_integrand_contours_K_1_H_007_W1_1_2_N_2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/2D_plots/N_2/H_007/Bergomi_integrand_contours_K_1_H_007_W2_1_2_N_2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Two dimensional Plotting of the integrand $I$ (in \eqref{BS_formula_rbergomi})  for $H=0.07$ and $N=2$, a)  function of $W_1$ coordinates, b) function of $W^2$ coordinates}
	\label{fig:Integrand_H_007_N_2_2D}
\end{figure}






\newpage
\subsubsection*{N=4, H=0.07}

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_007/Bergomi_integrand_K_1_H_007_W11_N_4}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_007/Bergomi_integrand_K_1_H_007_W12_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\vskip\baselineskip
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_007/Bergomi_integrand_K_1_H_007_W13_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_007/Bergomi_integrand_K_1_H_007_W14_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Plotting the integrand $I$ (in \eqref{BS_formula_rbergomi}) as a function of $W_1$ coordinates for $H=0.07$ and $N=4$.}
	\label{fig:Integrand_H_007_N_4_W_1_1}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_007/Bergomi_integrand_K_1_H_007_W21_N_4}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_007/Bergomi_integrand_K_1_H_007_W22_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\vskip\baselineskip
	
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_007/Bergomi_integrand_K_1_H_007_W23_N_4}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_007/Bergomi_integrand_K_1_H_007_W24_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Plotting the integrand $I$ (in \eqref{BS_formula_rbergomi}) as a function of $W_2$ coordinates for $H=0.07$ and $N=4$.}
	\label{fig:Integrand_H_007_N_4_W_2_1}
\end{figure}



\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/2D_plots/N_4/H_007/Bergomi_integrand_contours_K_1_H_007_W1_1_2_N_4}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/2D_plots/N_4/H_007/Bergomi_integrand_contours_K_1_H_007_W1_1_3_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Two dimensional Plotting of the integrand $I$ (in \eqref{BS_formula_rbergomi})  for $H=0.07$ and $N=4$, a)  function of $W_1^1$ and $W_1^2$ , b) function of $W_1^1$ and $W_1^3$ }
	\label{fig:Integrand_H_007_N_4_2D_W_1_2_3}
\end{figure}


\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/2D_plots/N_4/H_007/Bergomi_integrand_contours_K_1_H_007_W1_1_4_N_4}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/2D_plots/N_4/H_007/Bergomi_integrand_contours_K_1_H_007_W1_2_3_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Two dimensional Plotting of the integrand $I$ (in \eqref{BS_formula_rbergomi})  for $H=0.07$ and $N=4$, a)  function of $W_1^1$ and $W_1^4$ , b) function of $W_1^2$ and $W_1^3$ }
	\label{fig:Integrand_H_007_N_4_2D_W_1_4_2_3}
\end{figure}



\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/2D_plots/N_4/H_007/Bergomi_integrand_contours_K_1_H_007_W1_2_4_N_4}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/2D_plots/N_4/H_007/Bergomi_integrand_contours_K_1_H_007_W1_3_4_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Two dimensional Plotting of the integrand $I$ (in \eqref{BS_formula_rbergomi})  for $H=0.07$ and $N=4$, a)  function of $W_1^2$ and $W_1^4$ , b) function of $W_1^3$ and $W_1^4$ }
	\label{fig:Integrand_H_007_N_4_2D_W_1_3_3_4}
\end{figure}


\newpage
\subsubsection{Comparing the mixed differences rates}
In this section, we compare the mixed differences (first and second differences) rates for the standard case against the case where we do a partial change of measure wrt $W_1$ coordinates (see Section \ref{sec:Gaussian Hermite Quadrature with importance sampling}), for the case of $H=0.07$ and  $N=4$ time steps. From figures (\ref{fig:first_diff_comp_K_1_H_007_W_1},\ref{fig:first_diff_comp_K_1_H_007_W_2},\ref{fig:second_diff_comp_K_1_H_007_W_1},\ref{fig:second_diff_comp_K_1_H_007_W_1_2},\ref{fig:second_diff_comp_K_1_H_007_W_2}), we may notice that we face a bad behavior for the second differences, for the case without change of measure, which may explain the poor performance observed for MISC. This bad behavior is resolved when doing the partial change of measure. We obtained better results when using a measure change based on spectral decomposition rather than Cholesky decomposition. therefore by doing the change of measure, we obtained a more robust MISC solver.

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_mixed_error_rates/without_change_measure/N_4/H_007/first_difference_rbergomi_4steps_H_007_K_1_totally_hierarch_with_rate_W1}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_mixed_error_rates/partial_change_measure/N_4/H_007/first_difference_rbergomi_4steps_H_007_K_1_totally_hierarch_with_rate_W1_change_measure_part_spec}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)), for $W^1$, for $K=1$, $H=0.07$: a) Without measure change b) With measure change}
	\label{fig:first_diff_comp_K_1_H_007_W_1}
\end{figure}


\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_mixed_error_rates/without_change_measure/N_4/H_007/mixed_difference_order2_rbergomi_4steps_H_007_K_1_totally_hierarch_with_rate_W1}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_mixed_error_rates/partial_change_measure/N_4/H_007/mixed_difference_order2_rbergomi_4steps_H_007_K_1_totally_hierarch_with_rate_W1_change_measure_part_spec}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  second order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)), for $W^1$, for $K=1$, $H=0.07$: a) Without measure change b) With measure change}
	\label{fig:second_diff_comp_K_1_H_007_W_1}
\end{figure}




\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_mixed_error_rates/without_change_measure/N_4/H_007/mixed_difference_order2_rbergomi_4steps_H_007_K_1_totally_hierarch_with_rate_W1_2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_mixed_error_rates/partial_change_measure/N_4/H_007/mixed_difference_order2_rbergomi_4steps_H_007_K_1_totally_hierarch_with_rate_W1_2_change_measure_part_spec}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  second order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)), for $W^1$, for $K=1$, $H=0.07$: a) Without measure change b) With measure change}
	\label{fig:second_diff_comp_K_1_H_007_W_1_2}
\end{figure}



\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_mixed_error_rates/without_change_measure/N_4/H_007/first_difference_rbergomi_4steps_H_007_K_1_totally_hierarch_with_rate_W2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_mixed_error_rates/partial_change_measure/N_4/H_007/first_difference_rbergomi_4steps_H_007_K_1_totally_hierarch_with_rate_W2_change_measure_part_spec}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)), for $W^2$, for $K=1$, $H=0.07$: a) Without measure change b) With measure change}
	\label{fig:first_diff_comp_K_1_H_007_W_2}
\end{figure}


\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_mixed_error_rates/without_change_measure/N_4/H_007/mixed_difference_order2_rbergomi_4steps_H_007_K_1_totally_hierarch_with_rate_W2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_mixed_error_rates/partial_change_measure/N_4/H_007/mixed_difference_order2_rbergomi_4steps_H_007_K_1_totally_hierarch_with_rate_W2_change_measure_part_spec}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  second order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)), for $W^2$, for $K=1$, $H=0.07$: a) Without measure change b) With measure change}
	\label{fig:second_diff_comp_K_1_H_007_W_2}
\end{figure}

\newpage

\subsection{Numerical results for the case without change of measure}
\newpage
\subsubsection{Weak error plots} \label{sec:Weak error plots_no_change}
In this section, I include the results of weak error rates for the case without change of measure for both cases without and with Richardson extrapolation (level $1$ and $2$),  for $H \in \{0.43,0.07\}$. The reference solution was computed with $N=500$ time steps. We note that the weak errors plotted here corresponds to relative errors.
 

\subsubsection*{Without Richardson extrapolation}
From figures (\ref{fig:Weak_rate_H_043_without_rich} and \ref{fig:Weak_rate_H_007_without_rich}), we see that for both cases $H \in \{0.43,0.07\}$, we get a weak error of order $\Delta t$. The upper and lower bounds are $95\%$ confidence interval.



\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/without_richardson/H_043/weak_convergence_order_Bergomi_H_043_K_1_M_10_5_CI_relative}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/without_richardson/H_043/weak_convergence_order_differences_Bergomi_H_043_K_1_M_10_5_CI_relative}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of the weak error for $H=0.43$ $K=1$, without Richardson extraploation, using MC with $M=10^5$: a) $\abs{\expt{g(X_{\Delta t})}-g(X)}$  b) $\abs{\expt{g(X_{\Delta t})-g(X_{\Delta t/2})}}$ }
	\label{fig:Weak_rate_H_043_without_rich}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/without_richardson/H_007/weak_convergence_order_Bergomi_H_007_K_1_M_10_6_CI_relative}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/without_richardson/H_007/weak_convergence_order_differences_Bergomi_H_007_K_1_M_10_6_CI_relative}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of the weak error for $H=0.07$ $K=1$, without Richardson extraploation, using MC with $M=10^5$: a) $\abs{\expt{g(X_{\Delta t})}-g(X)}$  b) $\abs{\expt{g(X_{\Delta t})-g(X_{\Delta t/2})}}$ }
	\label{fig:Weak_rate_H_007_without_rich}
\end{figure}
\newpage
\subsubsection*{With Richardson extrapolation (level 1)}
From figures (\ref{fig:Weak_rate_H_043_with_rich} and \ref{fig:Weak_rate_H_007_with_rich}), we see that for both cases $H \in \{0.43,0.07\}$, we get a weak error of order $\Delta t^2$ (We can see this from the first points, however I think the last points are influenced by the statistical error). The upper and lower bounds are $95\%$ confidence interval.
\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_richardson/H_043/weak_convergence_order_Bergomi_H_043_K_1_M_10_6_CI_richardson_relative}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_richardson/H_043/weak_convergence_order_differences_Bergomi_H_043_K_1_M_10_6_CI_richardson_relative}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of the weak error for $H=0.43$ $K=1$, with Richardson extraploation, using MC with $M=10^6$: a) $\abs{\expt{2 g(X_{\Delta t/2}) -g(X_{\Delta t})}-g(X)}$  b) $\abs{\expt{3 g(X_{\Delta t/2})-g(X_{\Delta t})-2 g(X_{\Delta t/4})}}$ }
	\label{fig:Weak_rate_H_043_with_rich}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_richardson/H_007/weak_convergence_order_Bergomi_H_007_K_1_richardson_relative_M_10_6}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_richardson/H_007/weak_convergence_order_differences_Bergomi_H_007_K_1_richardson_relative_M_10_6}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of the weak error for $H=0.07$ $K=1$, with Richardson extraploation, using MC with $M=10^6$: a) $\abs{\expt{2 g(X_{\Delta t/2}) -g(X_{\Delta t})}-g(X)}$  b) $\abs{\expt{3 g(X_{\Delta t/2})-g(X_{\Delta t})-2 g(X_{\Delta t/4})}}$ }
	\label{fig:Weak_rate_H_007_with_rich}
\end{figure}




\newpage
\subsubsection*{With Richardson extrapolation (level 2)}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_richardson/H_043/weak_convergence_order_Bergomi_H_043_K_1_richardson_level2_relative_M_10_6}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_richardson/H_043/weak_convergence_order_differences_Bergomi_H_043_K_1_richardson_level2_relative_M_10_6}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of the weak error for $H=0.43$ $K=1$, with Richardson extraploation, using MC with $M=10^6$: a) $\abs{\frac{1}{3}\expt{8 g(X_{\Delta t/4}) -6g(X_{\Delta t/2}) +g(X_{\Delta t})}-g(X)}$  b) $\abs{\frac{1}{3}\expt{-8 g(X_{\Delta t/8}) +14g(X_{\Delta t/4})-7 (X_{\Delta t/2}) +g(X_{\Delta t})}}$}
	\label{fig:Weak_rate_H_043_with_rich_level2}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_richardson/H_007/weak_convergence_order_Bergomi_H_007_K_1_richardson_level2_relative_M_10_6_2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_richardson/H_007/weak_convergence_order_differences_Bergomi_H_007_K_1_richardson_level2_relative_M_10_6_2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of the weak error for $H=0.07$ $K=1$, with Richardson extraploation (level $2$), using MC with $M=10^6$: a) $\abs{\frac{1}{3}\expt{8 g(X_{\Delta t/4}) -6g(X_{\Delta t/2}) +g(X_{\Delta t})}-g(X)}$  b) $\abs{\frac{1}{3}\expt{-8 g(X_{\Delta t/8}) +14g(X_{\Delta t/4})-7 (X_{\Delta t/2}) +g(X_{\Delta t})}}$} 
	\label{fig:Weak_rate_H_007_with_rich_level2}
\end{figure}




\newpage
\subsubsection{Comparing relative errors using hierarchical representation }
\red{We note that these are preliminary results since we observed an over-estimated tolerance for MISC solver. We need to figure out a way to define the adequate procedure to use the right MISC tolerance.}
%For our numerical tests, we coupled the C++ implementation used in \cite{bayer2016pricing} with the MISC library, and for comparison purposes we compare our results to the same code but with MC method, for $M=10^6$ paths. 

 The results were reported for $H \in \{0.43,0.07\}$, and number of time steps $N \in \{2,4,8,16\}$.  Also, we use $S_0=1$, so the options will be prices in terms of the moneyness $K$, where $K$ is the strike price.  


In the following, we compare the  relative errors for H $\in \{0.43,0.07\}$ (see appendices \ref{appendix:Case $H=0.43$, Call prices for different methods} and \ref{appendix:Case $H=0.07$, Call prices for different methods} for the values of Call option prices). We note that for each case the reference solution was computed for $N=500$ (number of time steps) using MC with $10^6$ samples. In each case  we report the results for 3 scenarios: i) Without using Richardson extrapolation, ii) Using level $1$ Richardson extrapoaltion and  iii) Using level $2$ Richardson extrapoaltion. Tables (\ref{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.43$}, \ref{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.43$ , using Richardson extrapolation}, \ref{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.43$ , using Richardson extrapolation_level2})  coresspond to $H=0.43$ and tables (\ref{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.07$}, \ref{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.07$ , using Richardson extrapolation}, \ref{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.07$ , using Richardson extrapolation_level2})  coresspond to $H=0.07$.

Given the normalized bias computed by MC method  (reported as bold values in the tables), we report in red in each table the smallest tolerance that MISC required to get below that relative bias (I do not put values for smaller tolerances, once the required bias is reached).


From the tables below, we have the following observations:

\begin{itemize}
	\item Using Richardson extrapoaltion, we got a significant improvement for the relative error with the use of minimal time steps. For instance, for $H=0.43$, we achieved around $8\%$ of  relative error, with $16$ time steps when not using Richardson extrapolation (see table \ref{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.43$}). However, When using level $1$ of Richardson extrapolation (see table \ref{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.43$ , using Richardson extrapolation}),  we achieved around $6\%$ of  relative error, with  only $2$ time steps in the coarse level, and we got around  $1\%$ of  relative error, with   $4$ time steps in the coarse level. A more significant improvement is seen with level $2$ of Richardson extrapolation, in fact, with just $1$ step in the coarse level, we got around $3\%$ percent of relative error.
	\item For $H=0.07$, we achieved around $8\%$ of  relative error, with $16$ time steps when not using Richardson extrapolation (see table \ref{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.07$}). However, When using level $1$ of Richardson extrapolation (see table \ref{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.07$ , using Richardson extrapolation}),  we achieved around $5\%$ of  relative error, with  only $2$ time steps in the coarse level, and we got below  $1\%$ of  relative error, with   $4$ time steps in the coarse level. We observed a less significant improvement when using levle $2$ of Ricchardson extrapolation, compared to the case of $H=0.43$.
	
\end{itemize}







%\begin{figure}[!h]
%	\begin{center}
%		\includegraphics[scale=0.5]{./figures/rBergomi_weak_error/weak_RT.pdf}
%		\caption{The weak error of rBergomi model}
%		\label{fig:rBergomi_weak_error}
%	\end{center}
%\end{figure}

%We note that for some cases, the convergence becomes extremely slow (either the bias stagnates at one value or it keeps increasing or decreasing without reaching the prescribed tolerance) specially when we are close to at-the money option ($K$ close to 1), we do not put values for those cases. We also remark that we have better agreement between the results of MISC coupled with the C++ code and the MC method using the python code form \cite{mccrickerd2017turbocharging}, for small values of moneyness.

%In Section \ref{sec:MISC plots}, we show the convergence plots given by MISC library for the cases of $H=\{0.43,0.07\}$ and $K=0.1$.


%Table \ref{table: Complexity rates for different number of time steps_rbergomi} summarizes the obtained complexity rates for different number of time steps (for more details, see Section \ref{sec:MISC plots}. 
%
%\begin{table}[h!]
%	\centering
%	\begin{tabular}{l*{6}{c}r}
%		Method \textbackslash  Steps             &  $4$ & $8$  & $16$   \\
%		\hline
%		without Richardson  extrapolation(hierarchical) $(H=0.43)$ & $-0.34$ & $-0.33$ & $-0.75$   \\
%		without Richardson  extrapolation (non hierarchical) $(H=0.43)$ & $-0.17$ & $-0.6$ & $-1$   \\
%		without Richardson  extrapolation (hierarchical) $(H=0.07)$ & $-0.64$ & $-0.84$ & $-2.5$   \\
%		without Richardson  extrapolation (total hierarchical) $(H=0.07)$ & $-0.70$ & $-0.88$ & $-2.7$   \\
%		without Richardson  extrapolation (non hierarchical) $(H=0.07)$ & $-0.67$ & $-1.6$ & $-2.9$   \\
%		\hline
%	\end{tabular}
%	\caption{Complexity rates for different number of time steps for $K=1$ and $H=\{0.43,0.07\}$}
%	\label{table: Complexity rates for different number of time steps_rbergomi}
%\end{table}




\subsubsection*{Case $H=0.43$, Relative error for different methods}
\label{sec:Case $H=0.43$, Relative error for different methods}

\begin{table}[h!]
	\centering
	\begin{tabular}{l*{6}{c}r}
		Method \textbackslash  Steps            & $2$ & $4$ & $8$ & $16$ &   \\
		\hline
		MISC ($TOl=5.10^{-1}$)  & $0.6011$ & $0.3497$ & $0.1910$ & $0.0969$  \\
		MISC ($TOl=2.10^{-1}$)  &  $0.6011$ & $0.3497$ &$0.1910$ & $\red{0.0801}$  \\
		MISC ($TOl=10^{-1}$)  & $0.6011$ & $0.3497$ & $0.2233$ & $0.1236$  \\
		MISC ($TOl=5.10^{-2}$)  & $0.6011$ & $0.3539$ & $0.1882$ & $0.1573$  \\
		MISC ($TOl=10^{-2}$)  & $\red{0.5126}$ & $0.3258$ & $0.1770$ & $0.0829$   \\	
		MISC ($TOl=5.10^{-3}$)  & $	0.4930$ & $0.3076$ & $0.1671$ & $-$   \\	
	    MISC ($TOl=10^{-3}$)  & $		0.5126$ & $\red{0.2935}$ & $\red{0.1503}$ & $-$   \\
	MISC ($TOl=10^{-4}$)  & $		0.5154$ & $0.2935$ & $-$ & $-$   \\
			MC method ($M=10^{6}$)   & $\mathbf{0.5154}$  & $\mathbf{0.2935}$  & $\mathbf{0.1545}$ & $\mathbf{0.0801}$  \\	
		\hline
	\end{tabular}
	\caption{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1$, $H=0.43$, without Richardson extrapolation}
	\label{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.43$}
\end{table}

\begin{table}[h!]
	\centering
	\begin{tabular}{l*{5}{c}r}
		Method \textbackslash  Steps    &$1-2$        & $2-4$ & $4-8$ & $8-16$  \\
		\hline
		MISC ($TOl=5.10^{-1}$)  &$0.9059$ & $0.0997$ & $0.0323$ & $\red{0.0028}$  \\
		MISC ($TOl=10^{-1}$)  &$0.9059$ &$0.0997$ & $0.1025$ & $0.0688$ \\
		MISC ($TOl=5.10^{-2}$)  &$0.9059$ & $0.1671$ & $0.0857$ & $0.0646$   \\
		MISC ($TOl=10^{-2}$)  & $0.7374$ &$0.0969$ & $0.0463$ & $0.0028$ \\		
			MISC ($TOl=5.10^{-3}$)  & $0.7205$ &$0.0941$ & $0.0211$ & $-$ \\	
				MISC ($TOl=10^{-3}$)  & $0.7191$ & $0.0758$ & $\red{0.0112}$ & $-$ \\	
					MISC ($TOl=5.10^{-4}$)  &$\red{0.7129}$ & $\red{0.0609}$ & $-$ & $-$ \\
		MC method ($M=10^{6}$)&$ \mathbf{0.7133}$    & $\mathbf{0.0698}$  & $\mathbf{0.0160}$  & $\mathbf{0.0035}$ \\
		\hline
	\end{tabular}
	\caption{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1$, $H=0.43$, using Richardson extrapolation (level $1$)}
	\label{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.43$ , using Richardson extrapolation}
\end{table}



\begin{table}[h!]
	\centering
	\begin{tabular}{l*{5}{c}r}
		Method \textbackslash  Steps    &$1-2-4$        & $2-4-8$ & $4-8-16$   \\
		\hline
		MISC ($TOl=5.10^{-1}$)  &$ 0.1699$ & $\red{0.0098}$ & $ 0.0056$   \\
			MISC ($TOl=2.10^{-1}$)  &$ 0.1699$ &$-$ & $\red{ 0.0014}$  \\
		MISC ($TOl=10^{-1}$)  &$0.2037$ &$-$ & $-$  \\
		MISC ($TOl=5.10^{-2}$)  &$\red{0.0295}$ & $-$ & $-$  \\
		MC method ($M=10^{6}$)&$\mathbf{0.1440}$    & $ \mathbf{0.0180}  $  & $\mathbf{0.0023}$   \\
		\hline
	\end{tabular}
	\caption{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1$, $H=0.43$, using Richardson extrapolation (level $2$)}
	\label{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.43$ , using Richardson extrapolation_level2}
\end{table}
\newpage



\subsubsection*{Case $H=0.07$, Relative error for different methods}
\label{sec:Case $H=0.07$, Relative error for different methods}
\begin{table}[h!]
	\centering
	\begin{tabular}{l*{6}{c}r}
		Method \textbackslash  Steps            & $2$ & $4$ & $8$ & $16$ &   \\
		\hline
			MISC ($TOl=5.10^{-1}$)  & $\red{0.3662}$ & $\red{0.1578}$ & $\red{0.1010}$ & $\red{0.0758}$  \\
		MISC ($TOl=10^{-1}$)  & $0.3662$ &  $0.1578$ & $-$ & $-$  \\
		MISC ($TOl=5.10^{-2}$)        & $0.3662$ &$-$ &  $-$ &  $-$ \\
		MISC ($TOl=10^{-2}$)    & $-$ & $-$  & $-$ & $-$  \\	
		MC method ($M=10^{6}$)   & $\mathbf{0.5354}$  & $\mathbf{0.2879}$  & $\mathbf{0.1515}$ & $\mathbf{0.0783}$  \\	
		\hline
	\end{tabular}
	\caption{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1$, $H=0.07$, without Richardson extrapolation}
	\label{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.07$}
\end{table}





\begin{table}[h!]
	\centering
	\begin{tabular}{l*{5}{c}r}
		Method \textbackslash  Steps &$1-2$             & $2-4$ & $4-8$ & $8-16$ \\
		\hline
		MISC ($TOl=5.10^{-1}$)  &$\red{0.5682}$ & $\red{0.0505}$ & $0.1389$ & $0.1604$ \\
		MISC ($TOl=16.10^{-2}$)  &$0.5682$ & $0.0505$ & $0.1389$ & $\red{0.0038}$  \\
		MISC ($TOl=10^{-1}$)  &$0.5682$ &  $0.0505$ & $ 0.1692$ & $-$ \\
		MISC ($TOl=5.10^{-2}$) &$0.5682$ &  $ 0.1465$ & $\red{0.0088}$ & $-$   \\
		MISC ($TOl=10^{-2}$)&$-$ &  $0.0669$ & $0.0088$ & $-$ \\	
			MC method ($M=10^{6}$)  &$\mathbf{0.8915}$  & $\mathbf{0.0537}$  & $\mathbf{0.0129}$  & $\mathbf{0.0043}$ \\
		\hline	
	
	\end{tabular}
	\caption{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1$, $H=0.07$, using Richardson extrapolation (level $1$)}
	\label{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.07$ , using Richardson extrapolation}
\end{table}



\begin{table}[h!]
	\centering
	\begin{tabular}{l*{5}{c}r}
		Method \textbackslash  Steps &$1-2-4$             & $2-4-8$ & $4-8-16$   \\
		\hline
		MISC ($TOl=5.10^{-1}$)  &$0.2563$ & $ 0.1692$ & $ 0.1679
		$   \\
		MISC ($TOl=10^{-1}$)  &$0.2563$ &  $0.1566$ & $\red{  0.0025}$  \\
		MISC ($TOl=7.10^{-2}$) &$  0.3005$ &  $  \red{0.0227}$ & $-$    \\
		MISC ($TOl=5.10^{-2}$) &$0.4874$ &  $  -$ & $-$    \\
		MISC ($TOl=10^{-2}$)&$ \red{0.1742}$ &  $-$ & $-$  \\	
		MC method ($M=10^{6}$)  &$\mathbf{0.2231}$  & $  \mathbf{0.0279}$  & $\mathbf{0.0035}$ \\
		\hline	
		
	\end{tabular}
	\caption{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1$, $H=0.07$, using Richardson extrapolation (level $2$)}
	\label{Relative error of Call option price of the different tolerances for different number of time steps. Case $K=1, H=0.07$ , using Richardson extrapolation_level2}
\end{table}





%\subsection{Quadrature error vs work for different } \label{sec:Complexity  error plots}



%\begin{table}[h!]
%	\centering
%	\begin{tabular}{l*{6}{c}r}
%		Method \textbackslash  Steps            & $2$ & $4$ & $8$ & $16$  \\
%		\hline
%		MISC ($TOl=10^{-1}$)  & $0.2156$ & $0.2002$ &  $0.2002$ &  $0.1910$  \\
%		MISC ($TOl=10^{-2}$)  &  $0.2474$ &  $0.2378$ &  $0.2378$ & $-$  \\
%		MISC ($TOl=10^{-3}$)        &  $0.2505$ & $0.2377$ &   $-$ &  $-$ \\
%		MISC ($TOl=10^{-4}$)    &  $0.25$ &  $0.2378$  & $-$ & $-$  \\
%		%		MC method ($M=10^{6}$)    &  $0.6326$ &  $0.6332$  &  $0.6330$ &  $0.6337$  \\
%		MC method ($M=10^{6}$)   & $\underset{(4.72e-07)}{0.2499} $   & $\underset{(2.45e-07)}{0.2378} $  & $\underset{(1.80e-07)}{0.2310}$ & $\underset{(1.57e-07)}{0.2275} $  \\			
%		\hline
%	\end{tabular}
%	\caption{ Call option price of the different methods for different number of time steps. Case $K=0.8$}
%	\label{table: Call option price of the different methods for different number of time steps. Case $K=0.8$_H_007}
%\end{table}
%



%
%
%\begin{table}[h!]
%	\centering
%	\begin{tabular}{l*{6}{c}r}
%		Method \textbackslash  Steps            & $2$ & $4$ & $8$ & $16$  \\
%		\hline
%		MISC ($TOl=10^{-1}$)  & $0.0288$  & $0.0102$   & $0.0025$   &  $0.0005 $ \\
%		MISC ($TOl=10^{-2}$)  & $0.0501$  & $0.0161$ &   $0.0025$  &   $0.0005$  \\
%		MISC ($TOl=10^{-3}$)        &  $0.0515$ & $0.0335$  &  $-$  &   $-$ \\
%		MISC ($TOl=10^{-4}$)    & $0.0525$   &  $-$   & $-$ & $-$  \\
%		%		MC method ($M=10^{6}$)    &  $0.8646$  &   $0.8647$   &   $0.8643$  &   $0.8646$   \\
%		MC method ($M=10^{6}$)   & $\underset{(2.68e-07)}{0.0518} $   & $\underset{(1.85e-07)}{0.0339} $  & $\underset{(1.44e-07)}{0.0237}$ & $\underset{(6.61e-08)}{0.0177} $  \\		
%		\hline
%	\end{tabular}
%	\caption{ Call option price of the different methods for different number of time steps. Case $K=1.2$}
%	\label{table: Call option price of the different methods for different number of time steps. Case $K=1.2$_H_007}
%\end{table}



%
%\begin{figure}[!h]
%	\centering
%	\begin{subfigure}{.5\textwidth}
%		\centering
%		\includegraphics[width=0.95\linewidth]{./figures/payoff_plots_H_007/rBergomi_payoff_2steps_wrt_monyeness}
%		\caption{}
%		\label{fig:rBergomi_payoff_4steps_wrt_monyeness_sub1}
%	\end{subfigure}%
%	\begin{subfigure}{.5\textwidth}
%		\centering
%		\includegraphics[width=0.95\linewidth]{./figures/payoff_plots_H_007/rBergomi_payoff_4steps_wrt_monyeness}
%		\caption{ }
%		\label{fig:rBergomi_payoff_4steps_wrt_monyeness_sub2}
%	\end{subfigure}%
%	\caption{Black Scholes payoff for rBergomi model as a function of moneyness a) $2$  time steps, b) $4$  time steps.}
%	\label{fig:rBergomi_payoff_4steps_wrt_monyeness_1}
%\end{figure}
%
%\begin{figure}[!h]
%	\centering
%	\begin{subfigure}{.5\textwidth}
%		\centering
%		\includegraphics[width=0.95\linewidth]{./figures/payoff_plots_H_007/rBergomi_payoff_8steps_wrt_monyeness}
%		\caption{}
%		\label{fig:rBergomi_payoff_4steps_wrt_monyeness_sub3}
%	\end{subfigure}%
%	\begin{subfigure}{.5\textwidth}
%		\centering
%		\includegraphics[width=0.95\linewidth]{./figures/payoff_plots_H_007/rBergomi_payoff_16steps_wrt_monyeness}
%		\caption{ }
%		\label{fig:rBergomi_payoff_4steps_wrt_monyeness_sub4}
%	\end{subfigure}%
%	\caption{Black Scholes payoff for rBergomi model as a function of moneyness a) $8$  time steps, b) $16$  time steps.}
%	\label{fig:rBergomi_payoff_4steps_wrt_monyeness_2}
%\end{figure}
%



\newpage
\subsection{Numerical results for the case with change of measure}
\subsubsection{Weak error plots} \label{sec:Weak error plots_with_change}
In this section, I include the results of weak error rates for the case with change of measure for both cases without and with Richardson extrapolation,  for $H =0.07$. The reference solution was computed with $N=500$ time steps. We note that we limit the maximum number of changed coordinates  up to $4$, due to practical purposes related to the optimization procedure.  We note that the weak errors plotted here corresponds to relative errors.


\subsubsection*{Without Richardson extrapolation}
From figure \ref{fig:Weak_rate_H_007_without_rich_change_meausre}), we see that for $H=0.07$, we get a weak error of order $\Delta t$. The upper and lower bounds are $95\%$ confidence interval.
\begin{figure}
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_change_measure/without_rich/H_007/weak_convergence_order_Bergomi_H_007_K_1_M_10_5_CI_relative_measure_change_spec}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_change_measure/without_rich/H_007/weak_convergence_order_differences_Bergomi_H_007_K_1_M_10_5_CI_relative_measure_change_spec}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of the weak error for $H=0.07$ $K=1$, without Richardson extraploation, using MC with $M=10^5$: a) $\abs{\expt{g(X_{\Delta t})}-g(X)}$  b) $\abs{\expt{g(X_{\Delta t})-g(X_{\Delta t/2})}}$ }
	\label{fig:Weak_rate_H_007_without_rich_change_meausre}
\end{figure}
\newpage
\subsubsection*{With Richardson extrapolation (level 1)}
From figure \ref{fig:Weak_rate_H_007_with_rich_change_measure} , we see that  for $H=0.07$, we get a weak error of order $\Delta t^2$. The upper and lower bounds are $95\%$ confidence interval.
\begin{figure}[h!]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_change_measure/with_rich/weak_convergence_order_Bergomi_H_007_K_1_M_10_5_CI_relative_measure_change_level_1_spec}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rBergomi_weak_error_rates/with_change_measure/with_rich/weak_convergence_order_differences_Bergomi_H_007_K_1_M_10_5_CI_relative_measure_change_level_1_spec}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of the weak error for $H=0.07$ $K=1$, with Richardson extraploation, using MC with $M=10^6$: a) $\abs{\expt{2 g(X_{\Delta t/2}) -g(X_{\Delta t})}-g(X)}$  b) $\abs{\expt{3 g(X_{\Delta t/2})-g(X_{\Delta t})-2 g(X_{\Delta t/4})}}$ }
	\label{fig:Weak_rate_H_007_with_rich_change_measure}
\end{figure}



\newpage
\subsubsection{Comparing relative errors }
\red{ We need to figure out a way to define the adequate procedure to use the right MISC tolerance, since we observed an over-estimated tolerance for MISC solver when used for the case without change of measure.}







 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%References
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\bibliographystyle{plain}
\bibliography{smoothing_rBergomi} 




\appendix



\newpage
\section{additional results}
\subsection{Integrand plotting wrt different random inputs N=2, H=0.43}\label{Appendix:Integrand plotting wrt different random inputs N=2, H=0.43}


\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_2/H_043/Bergomi_integrand_K_1_H_043_W11_N_2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_2/H_043/Bergomi_integrand_K_1_H_043_W12_N_2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Plotting the integrand $I$ (in \eqref{BS_formula_rbergomi}) as a function of $W^1$ coordinates for $H=0.43$ and $N=2$.}
	\label{fig:Integrand_H_043_N_2_W_1}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_2/H_043/Bergomi_integrand_K_1_H_043_W21_N_2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_2/H_043/Bergomi_integrand_K_1_H_043_W22_N_2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Plotting the integrand $I$ (in \eqref{BS_formula_rbergomi}) as a function of $W^2$ coordinates for $H=0.43$ and $N=2$.}
	\label{fig:Integrand_H_043_N_2_W_2}
\end{figure}



\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/2D_plots/N_2/H_043/Bergomi_integrand_contours_K_1_H_043_W1_1_2_N_2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/2D_plots/N_2/H_043/Bergomi_integrand_contours_K_1_H_043_W2_1_2_N_2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Two dimensional Plotting of the integrand $I$ (in \eqref{BS_formula_rbergomi})  for $H=0.43$ and $N=2$, a)  function of $W^1$ coordinates, b) function of $W^2$ coordinates}
	\label{fig:Integrand_H_043_N_2_2D}
\end{figure}


\newpage
\subsection{Integrand plotting wrt different random inputs: N=4, H=0.43}\label{Appendix:Integrand plotting wrt different random inputs: N=4, H=0.43}


\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.475\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_043/Bergomi_integrand_K_1_H_043_W11_N_4}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.475\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_043/Bergomi_integrand_K_1_H_043_W12_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\vskip\baselineskip
	\begin{subfigure}[b]{0.475\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_043/Bergomi_integrand_K_1_H_043_W13_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\quad
	\begin{subfigure}[b]{0.475\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_043/Bergomi_integrand_K_1_H_043_W14_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Plotting the integrand $I$ (in \eqref{BS_formula_rbergomi}) as a function of $W^1$ coordinates for $H=0.43$ and $N=4$.}
	\label{fig:Integrand_H_043_N_4_W_1_1}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.475\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_043/Bergomi_integrand_K_1_H_043_W21_N_4}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.475\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_043/Bergomi_integrand_K_1_H_043_W22_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	
	\vskip\baselineskip
	
	\begin{subfigure}[b]{0.475\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_043/Bergomi_integrand_K_1_H_043_W23_N_4}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}
	\hfill
	\begin{subfigure}[b]{0.475\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/integrand_plotting_rBergomi/1D_plots/N_4/H_043/Bergomi_integrand_K_1_H_043_W24_N_4}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	\caption{Plotting the integrand $I$ (in \eqref{BS_formula_rbergomi}) as a function of $W^2$ coordinates for $H=0.43$ and $N=4$.}
	
	\label{fig:Integrand_H_043_N_4_W_2_1}
\end{figure}


\newpage

\subsection{Case $H=0.43$, Call prices for different methods}\label{appendix:Case $H=0.43$, Call prices for different methods}

\begin{table}[h!]
	\centering
	\begin{tabular}{l*{6}{c}r}
		Method \textbackslash  Steps            & $2$ & $4$ & $8$ & $16$ &   \\
		\hline
		MISC ($TOl=5.10^{-1}$)  & $0.1140$ & $0.0961$ & $0.0848$ & $0.0781$  \\
		MISC ($TOl=2.10^{-1}$)  & $0.1140$ & $0.0961$ & $0.0848$ & $\red{0.0769}$  \\
		MISC ($TOl=10^{-1}$)  & $0.1140$ & $0.0961$ & $0.0871$ & $0.0800$  \\
		MISC ($TOl=5.10^{-2}$)  & $0.1140$ & $0.0964$ & $0.0846$ & $0.0824$  \\
		MISC ($TOl=10^{-2}$)  & $\red{0.1077}$ & $0.0944$ & $0.0838$ & $0.0771$  \\
		MISC ($TOl=5.10^{-3}$)  & $0.1063$ & $0.0931$ & $0.0831$ & $-$  \\
		MISC ($TOl=10^{-3}$)  & $0.1077$ & $\red{0.0921}$ & $\red{0.0819}$ & $-$  \\
		MISC ($TOl=10^{-4}$)  & $0.1079$ & $0.0921$ & $-$ & $-$  \\
		MC method ($M=10^{6}$)   & $\underset{(1.55e-04)}{0.1079}$ & $ \underset{(9.65e-05)}{0.0921}$  & $ \underset{(7.61e-05)}{0.0822}$ & $ \underset{(6.65e-05)}{0.0769}$ \\		
		
		\hline
	\end{tabular}
	\caption{ Call option price of the different methods for different number of time steps. Case $K=1$, $H=0.43$, without Richardson extrapolation.  The values between parentheses in the tables are the standard errors for MC method}
	\label{table: Call option price of the different methods for different number of time steps. Case $K=1$, $H=0.43$}
\end{table}

\begin{table}[h!]
	\centering
	\begin{tabular}{l*{6}{c}r}
		Method \textbackslash  Steps           &$1-2$ & $2-4$ & $4-8$ & $8-16$\\
		\hline
		MISC ($TOl=5.10^{-1}$)& $0.1357$  & $0.0783$ & $0.0735$ & $\red{0.0714}$ \\
		MISC ($TOl=10^{-1}$)  &$0.1357$  &$0.0783$ & $0.0785$ & $0.0761$  \\
		MISC ($TOl=5.10^{-2}$)  & $0.1357$ & $0.0831$ & $0.0773$ & $0.0758$   \\
		MISC ($TOl=10^{-2}$)  & $0.1237$ &$0.0781$ & $0.0745$ & $0.0714$  \\
		MISC ($TOl=5.10^{-3}$)  & $0.1225$ &$0.0779$ & $0.0727$ & $-$  \\	
		MISC ($TOl=10^{-3}$)  & $0.1224$ &$0.0766$ & $\red{0.0720}$ & $-$ \\
		MISC ($TOl=5.10^{-4}$)  &$\red{0.1221}$ & $\red{0.0763}$ & $-$ & $-$ \\
		\hline
	\end{tabular}
	\caption{ Call option price of the different methods for different number of time steps. Case $K=1$, $H=0.43$, using Richardson extrapolation (level $1$)}
	\label{table: Call option price of the different methods for different number of time steps. Case $K=1$, using Richardson extrapolation}
\end{table}







\begin{table}[h!]
	\centering
	\begin{tabular}{l*{6}{c}r}
		Method \textbackslash  Steps           &$1-2-4$ & $2-4-8$ & $4-8-16$\\
		\hline
		MISC ($TOl=5.10^{-1}$)& $0.0591$  & $\red{0.0719}$ & $0.0708$  \\
		MISC ($TOl=2.10^{-1}$)  &$0.0591$ &$-$ & $\red{0.0711}$  \\
		MISC ($TOl=10^{-1}$)  &$0.0567$  &$-$ & $-$   \\
		MISC ($TOl=5.10^{-2}$)  & $\red{0.0733}$ & $-$ & $-$  \\
		\hline
	\end{tabular}
	\caption{ Call option price of the different methods for different number of time steps. Case $K=1$, $H=0.43$, using Richardson extrapolation (level 2)}
	\label{table: Call option price of the different methods for different number of time steps. Case $K=1$, using Richardson extrapolation_level2}
\end{table}


\newpage
\subsection{Case $H=0.07$, Call prices for different methods}\label{appendix:Case $H=0.07$, Call prices for different methods}

\begin{table}[h!]
	\centering
	\begin{tabular}{l*{6}{c}r}
		Method \textbackslash  Steps            & $2$ & $4$ & $8$ & $16$  \\
		\hline
		MISC ($TOl=5.10^{-1}$)  & $\red{0.1082}$ & $\red{0.0917}$ & $\red{0.0872}$ & $\red{0.0732}$  \\
		MISC ($TOl=10^{-1}$)  & $0.1082$ &  $0.0917$ & $-$ & $-$  \\
		MISC ($TOl=5.10^{-2}$)        & $0.1082$ &$-$ &  $-$ &  $-$ \\
		MISC ($TOl=10^{-2}$)    & $-$ & $-$  & $-$ & $-$  \\
		%				MC method ($M=10^{6}$)    & $0.0840$ & $0.0781$  & $0.0746$ & $0.0729$  \\
		MC method ($M=10^{6}$)   & $\underset{(1.05e-03)}{0.1216} $  & $\underset{(1.86e-04)}{0.1020} $  & $\underset{ (1.35e-04)}{0.0912}$ & $\underset {(1.08e-04)}{0.0854} $  \\		
		\hline
	\end{tabular}
	\caption{ Call option price of the different methods for different number of time steps. Case $K=1$, without Richardson extrapolation.  The values between parentheses in the tables are the standard errors for MC method}
	\label{table: Call option price of the different methods for different number of time steps. Case $K=1$, $H_007$}
\end{table}

\begin{table}[h!]
	\centering
	\begin{tabular}{l*{6}{c}r}
		Method \textbackslash  Steps    &$1-2$         & $2-4$ & $4-8$ & $8-16$\\
		\hline
		MISC ($TOl=5.10^{-1}$)  &$\red{0.1242}$ & $\red{0.0752}$ & $0.0682$ & $0.0665$ \\
		MISC ($TOl=16.10^{-2}$)  &$0.1242$ & $0.0752$ & $0.0682$ & $\red{0.0795}$  \\
		MISC ($TOl=10^{-1}$)  &$0.1242$ & $0.0752$ & $0.0658$ & $-$  \\
		MISC ($TOl=5.10^{-2}$)   &$0.1242$ & $0.0676$ & $\red{0.0799}$ & $-$   \\
		MISC ($TOl=10^{-2}$)  &$-$ & $0.0845$ & $0.0799$ & $-$  \\	
		\hline
	\end{tabular}
	\caption{ Call option price of the different methods for different number of time steps. Case $K=1$, $H=0.07$, using Richardson extrapolation (level $1$)}
	\label{table: Call option price of the different methods for different number of time steps. Case $K=1$, $H=0.07$, using Richardson extrapolation}
\end{table}



\begin{table}[h!]
	\centering
	\begin{tabular}{l*{6}{c}r}
		Method \textbackslash  Steps    &$1-2-4$         & $2-4-8$ & $4-8-16$ \\
		\hline
		MISC ($TOl=5.10^{-1}$)  &$0.0589$ & $0.0658$ & $0.0659$  \\
		MISC ($TOl=10^{-1}$)  &$0.0589$ & $0.0668$ & $\red{0.079}$   \\
		MISC ($TOl=7.10^{-2}$)   &$0.0554$ & $\red{0.0810}$ & $-$   \\
		MISC ($TOl=5.10^{-2}$)   &$0.0406$ & $-$ & $-$   \\
		MISC ($TOl=10^{-2}$)  &$\red{0.0654}$ & $-$ & $-$   \\	
		\hline
	\end{tabular}
	\caption{ Call option price of the different methods for different number of time steps. Case $K=1$, $H=0.07$, using Richardson extrapolation (level $2$)}
	\label{table: Call option price of the different methods for different number of time steps. Case $K=1$, $H=0.07$, using Richardson extrapolation_level2}
\end{table}






\newpage
\subsection{Motivation of the hierarchical representation and investigating the effect with respect to $H$ }\label{sec:mixed differences rbergomi_wrt_H}
In this section, we motivate the idea of using hierarchical representation (Brownian bridge construction) for buiding $W^1$ and $W^2$. 
\subsubsection{Totally Hierarchical}
In this section, we do both hierarchical transformation, based on brownian bridges, for both directions $W^1$ and $W^2$. We see clearly from figures (\ref{fig:first_diff_tot_hiera_W2},\ref{fig:second_diff_tot_hiera_W2}) the advantage of buiding  $W^2$ in a hierarchical fashion as $W^1$ 


\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/hierarchical/H_007/N_8/first_difference_rbergomi_8steps_H_007_K_1_hierarch_with_rate_W2.eps}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/total_hierarchical/first_difference_rbergomi_8steps_H_007_K_1_totally_hierarch_with_rate_W2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) Without hierarchical for $W_2$ b) With hierarchical for $W_2$}
	\label{fig:first_diff_tot_hiera_W2}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/hierarchical/H_007/N_8/mixed_difference_order2_rbergomi_8steps_H_007_K_1_hierarch_with_rate_W2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/total_hierarchical/mixed_difference_order2_rbergomi_8steps_H_007_K_1_totally_hierarch_with_rate_W2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  second order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) Without hierarchical for $W_2$ b) With hierarchical for $W_2$}
	\label{fig:second_diff_tot_hiera_W2}
\end{figure}


\newpage
\subsubsection{Hierarchical}
\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/hierarchical/H_043/N_8/first_difference_rbergomi_8steps_H_043_K_1_hierarch_with_rate_W1.eps}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/hierarchical/H_007/N_8/first_difference_rbergomi_8steps_H_007_K_1_hierarch_with_rate_W1.eps}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) $H=0.43$ b)  $H=0.07$}
	\label{fig:test2}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/hierarchical/H_043/N_8/first_difference_rbergomi_8steps_H_043_K_1_hierarch_with_rate_W2.eps}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/hierarchical/H_007/N_8/first_difference_rbergomi_8steps_H_007_K_1_hierarch_with_rate_W2.eps}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) $H=0.43$ b)  $H=0.07$}
	\label{fig:test2}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/hierarchical/H_043/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_1_hierarch_with_rate_W1}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/hierarchical/H_007/N_8/mixed_difference_order2_rbergomi_8steps_H_007_K_1_hierarch_with_rate_W1}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) $H=0.43$ b)  $H=0.07$}
	\label{fig:test2}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/hierarchical/H_043/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_1_hierarch_with_rate_W2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/hierarchical/H_007/N_8/mixed_difference_order2_rbergomi_8steps_H_007_K_1_hierarch_with_rate_W2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) $H=0.43$ b)  $H=0.07$}
	\label{fig:test2}
\end{figure}



\newpage
\subsubsection{Non  Hierarchical}
\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/non_hierarchical/H_043/N_8/first_difference_rbergomi_8steps_H_043_K_1_non_hierarch_with_rate_W1.eps}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/non_hierarchical/H_007/N_8/first_difference_rbergomi_8steps_H_007_K_1_non_hierarch_with_rate_W1.eps}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) $H=0.43$ b)  $H=0.07$}
	\label{fig:test2}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/non_hierarchical/H_043/N_8/first_difference_rbergomi_8steps_H_043_K_1_non_hierarch_with_rate_W2.eps}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/non_hierarchical/H_007/N_8/first_difference_rbergomi_8steps_H_007_K_1_non_hierarch_with_rate_W2.eps}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) $H=0.43$ b)  $H=0.07$}
	\label{fig:test2}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/non_hierarchical/H_043/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_1_non_hierarch_with_rate_W1}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/non_hierarchical/H_007/N_8/mixed_difference_order2_rbergomi_8steps_H_007_K_1_non_hierarch_with_rate_W1}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) $H=0.43$ b)  $H=0.07$}
	\label{fig:test2}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/non_hierarchical/H_043/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_1_non_hierarch_with_rate_W2}
		\caption{}
		\label{fig:sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/effect_H_differences/non_hierarchical/H_007/N_8/mixed_difference_order2_rbergomi_8steps_H_007_K_1_non_hierarch_with_rate_W2}
		\caption{}
		\label{fig:sub4}
	\end{subfigure}
	
	\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) $H=0.43$ b)  $H=0.07$}
	\label{fig:test2}
\end{figure}
\newpage

\subsection{Investigating mixed differences wrt $\rho$ }\label{sec:mixed differences rbergomi_wrt_rho}

\subsubsection*{N=4, K=1 }
\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_4/first_difference_rbergomi_4steps_H_043_K_1_rho__0_9_with_rate_W1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_4/first_difference_rbergomi_4steps_H_043_K_1_rho_0_with_rate_W1.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)) for $K=1$: a) $\rho=-0.9$ b)  $\rho=0.$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_4/mixed_difference_order2_rbergomi_4steps_H_043_K_1_rho__0__9_with_rate_W1}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_4/mixed_difference_order2_rbergomi_4steps_H_043_K_1_rho_0_with_rate_W1}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\rho=-0.9$ b)  $\rho=0.$}
\label{fig:test2}
\end{figure}

\newpage
\subsubsection*{N=8, K=1 }


\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_8/first_difference_rbergomi_8steps_H_043_K_1_rho__0_9_with_rate_W1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_8/first_difference_rbergomi_8steps_H_043_K_1_rho_0_with_rate_W1.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\rho=-0.9$ b)  $\rho=0.$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_1_rho__0_9_with_rate_W1}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_1_rho_0_with_rate_W1}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\rho=-0.9$ b)  $\rho=0.$}
\label{fig:test2}
\end{figure}


\newpage
\subsubsection*{N=4, K=0.8 }
\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_4/first_difference_rbergomi_4steps_H_043_K_0_8_rho__0_9_with_rate_W1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_4/first_difference_rbergomi_4steps_H_043_K_0_8_rho_0_with_rate_W1.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\rho=-0.9$ b)  $\rho=0.$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_4/mixed_difference_order2_rbergomi_4steps_H_043_K_0_8_rho__0_9_with_rate_W1}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_4/mixed_difference_order2_rbergomi_4steps_H_043_K_0_8_rho_0_with_rate_W1}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\rho=-0.9$ b)  $\rho=0.$}
\label{fig:test2}
\end{figure}

\newpage
\subsubsection*{N=8, K=0.8 }


\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_8/first_difference_rbergomi_8steps_H_043_K_0_8_rho__0_9_with_rate_W1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_8/first_difference_rbergomi_8steps_H_043_K_0_8_rho_0_with_rate_W1.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\rho=-0.9$ b)  $\rho=0.$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_0_8_rho__0_9_with_rate_W1}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_0_8_rho_0_with_rate_W1}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\rho=-0.9$ b)  $\rho=0.$}
\label{fig:test2}
\end{figure}


\newpage
\subsection{Investigating mixed differences wrt $\xi$ }\label{sec:mixed differences rbergomi_wrt_xi}

\subsubsection*{N=4, K=1 }
\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_4/first_difference_rbergomi_4steps_H_043_K_1_rho__0_9_with_rate_W1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_xi_differences/H_0_43_K_1/N_4/first_difference_rbergomi_4steps_H_043_K_1_xi_10__5_with_rate_W1.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\xi=0.235^2$ b)  $\xi=10^{-5}$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_4/mixed_difference_order2_rbergomi_4steps_H_043_K_1_rho__0__9_with_rate_W1}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_xi_differences/H_0_43_K_1/N_4/mixed_difference_order2_rbergomi_4steps_H_043_K_1_xi_10__5_with_rate_W1}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\xi=0.235^2$ b)  $\xi=10^{-5}$}
\label{fig:test2}
\end{figure}

\newpage
\subsubsection*{N=8, K=1 }


\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_8/first_difference_rbergomi_8steps_H_043_K_1_rho__0_9_with_rate_W1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_xi_differences/H_0_43_K_1/N_8/first_difference_rbergomi_8steps_H_043_K_1_xi_10__5_with_rate_W1.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\xi=0.235^2$ b)  $\xi=10^{-5}$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_1/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_1_rho__0_9_with_rate_W1}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_xi_differences/H_0_43_K_1/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_1_xi_10__5_with_rate_W1}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\xi=0.235^2$ b)  $\xi=10^{-5}$}
\label{fig:test2}
\end{figure}


\newpage
\subsubsection*{N=4, K=0.8 }
\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_4/first_difference_rbergomi_4steps_H_043_K_0_8_rho__0_9_with_rate_W1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_xi_differences/H_0_43_K_0_8/N_4/first_difference_rbergomi_4steps_H_043_K_0_8_xi_10__5_with_rate_W1.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\xi=0.235^2$ b)  $\xi=10^{-5}$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_4/mixed_difference_order2_rbergomi_4steps_H_043_K_0_8_rho__0_9_with_rate_W1}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_xi_differences/H_0_43_K_0_8/N_4/mixed_difference_order2_rbergomi_4steps_H_043_K_0_8_xi_10__5_with_rate_W1}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\xi=0.235^2$ b)  $\xi=10^{-5}$}
\label{fig:test2}
\end{figure}

\newpage
\subsubsection*{N=8, K=0.8 }


\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_8/first_difference_rbergomi_8steps_H_043_K_0_8_rho__0_9_with_rate_W1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_xi_differences/H_0_43_K_0_8/N_8/first_difference_rbergomi_8steps_H_043_K_0_8_xi_10__5_with_rate_W1.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\xi=0.235^2$ b)  $\xi=10^{-5}$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_rho_differences/H_0_43_K_0_8/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_0_8_rho__0_9_with_rate_W1}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/effect_xi_differences/H_0_43_K_0_8/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_0_8_xi_10__5_with_rate_W1}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  mixed order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $\xi=0.235^2$ b)  $\xi=10^{-5}$}
\label{fig:test2}
\end{figure}




\newpage
\subsection{Investigating mixed differences wrt moneyness $K$ }\label{sec:mixed differences rbergomi_wrt_moneyness}

\subsubsection*{Case $H=0.43$}
\subsubsection*{$N=8$ }
\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_043/N_8/first_difference_rbergomi_8steps_H_043_K_1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_043/N_8/first_difference_rbergomi_8steps_H_043_K_exp__4.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $K=1$ b)  $K=\operatorname{exp}(-4).$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_043/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_043/N_8/mixed_difference_order2_rbergomi_8steps_H_043_K_exp__4.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  second order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $K=1$ b)  $K=\operatorname{exp}(-4).$}
\label{fig:test2}
\end{figure}

\newpage
\subsubsection*{$N=16$ }


\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_043/N_16/first_difference_rbergomi_16steps_H_043_K_1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_043/N_16/first_difference_rbergomi_16steps_H_043_K_exp__4.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $K=1$ b)  $K=\operatorname{exp}(-4).$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_043/N_16/mixed_difference_order2_rbergomi_16steps_H_043_K_1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_043/N_16/mixed_difference_order2_rbergomi_16steps_H_043_K_exp__4.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  second order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $K=1$ b)  $K=\operatorname{exp}(-4).$}
\label{fig:test2}
\end{figure}



\newpage
\subsubsection*{Case $H=0.07$}
\subsubsection*{$N=8$ }

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_007/N_8/first_difference_rbergomi_8steps_H_007_K_1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_007/N_8/first_difference_rbergomi_8steps_H_007_K_exp__4.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $K=1$ b)  $K=\operatorname{exp}(-4).$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_007/N_8/mixed_difference_order2_rbergomi_8steps_H_007_K_1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_007/N_8/mixed_difference_order2_rbergomi_8steps_H_007_K_exp__4.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  second order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $K=1$ b)  $K=\operatorname{exp}(-4).$}
\label{fig:test2}
\end{figure}


\newpage
\subsubsection*{$N=16$ }
\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_007/N_16/first_difference_rbergomi_16steps_H_007_K_1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_007/N_16/first_difference_rbergomi_16steps_H_007_K_exp__4.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  first order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $K=1$ b)  $K=\operatorname{exp}(-4).$}
\label{fig:test2}
\end{figure}

\begin{figure}[h!]
\centering
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_007/N_16/mixed_difference_order2_rbergomi_16steps_H_007_K_1.eps}
\caption{}
\label{fig:sub3}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
\centering
\includegraphics[width=1\linewidth]{./figures/mixed_diff_second_way/H_007/N_16/mixed_difference_order2_rbergomi_16steps_H_007_K_exp__4.eps}
\caption{}
\label{fig:sub4}
\end{subfigure}

\caption{The rate of convergence of  second order differences $\abs{\Delta E_{\beta}}$ ($\beta=\mathbf{1}+k \bar{\beta}$)): a) $K=1$ b)  $K=\operatorname{exp}(-4).$}
\label{fig:test2}
\end{figure}


\newpage
\subsection{Convergence plots using MISC ($H=0.43$)}\label{sec:Convergence plots using MISC_H_043}
\newpage
\subsubsection*{Case of $2$ time steps, $K=e^{-4}$}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_2_steps_K_e__4/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_2_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_2_steps_K_e__4/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_2_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_2_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_2_steps_K_e__4/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_2_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_2_steps_K_e__4/levels_error_rate.pdf}
		\caption{ The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_2_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_2_steps_2}
\end{figure}
\newpage
\subsubsection*{Case of $2$ time steps, $K=1.2$}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_2_steps_K_1_2/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_2_steps_K_1_2_sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_2_steps_K_1_2/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_2_steps_K_1_1_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_2_steps_K_1_2_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_2_steps_K_1_2/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_2_steps_K_1_2_sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_2_steps_K_1_2/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_2_steps_K_1_2_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_2_steps_K_1_2_2}
\end{figure}


\newpage
\subsubsection*{Case of $4$ time steps, $K=e^{-4}$}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_4_steps_K_e__4/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_4_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_4_steps_K_e__4/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_4_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_4_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_4_steps_K_e__4/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_4_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_4_steps_K_e__4/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_4_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_4_steps_2}
\end{figure}
\newpage
\subsubsection*{Case of $4$ time steps, $K=1.2$}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_4_steps_K_1_2/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_4_steps_K_1_2_sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_4_steps_K_1_2/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_4_steps_K_1_2_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_4_steps_K_1_2_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_4_steps_K_1_2/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_4_steps_K_2_sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_4_steps_K_1_2/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_4_steps_K_1_2_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_4_steps_K_1_2_2}
\end{figure}



\newpage
\subsubsection*{Case of $8$ time steps, $K=e^{-4}$}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_8_steps_K_e__4/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_8_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_8_steps_K_e__4/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_8_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_8_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_8_steps_K_e__4/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_8_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_8_steps_K_e__4/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_8_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_8_steps_2}
\end{figure}



\newpage
\subsubsection*{Case of $8$ time steps, $K=1.2$}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_8_steps_K_1_2/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_8_steps_K_1_2_sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_8_steps_K_1_2/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_8_steps_K_1_2_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_8_steps_K_1_2_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_8_steps_K_1_2/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_8_steps_K_1_2_sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_8_steps_K_1_2/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_8_steps_K_1_2_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_8_steps_K_1_2_2}
\end{figure}


\newpage
\subsubsection*{Case of $16$ time steps, $K=e^{-4}$}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_16_steps_K_e__4/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_16_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_16_steps_K_e__4/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_16_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_16_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_16_steps_K_e__4/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_16_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_16_steps_K_e__4/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_16_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_16_steps_2}
\end{figure}


\newpage

\subsubsection*{Case of $16$ time steps, $K=1.2$}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_16_steps_K_1_2/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_16_steps_K_1_2_sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/rbergomi_16_steps_K_1_2/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_16_steps_K_1_2_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_16_steps_K_1_2_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_16_steps_K_1_2/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_16_steps_K_1_2_sub3}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/rbergomi_16_steps_K_1_2/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_16_steps_K_1_2_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model.}
	\label{fig:misc_rbergomi_16_steps_K_1_2_2}
\end{figure}



\newpage
\subsection{MISC plots}\label{sec:MISC plots}
\subsection{Non Hierarchical}

\subsubsection*{H=0.43}
\newpage
\subsubsection*{Case of $8$ time steps}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/non_hierarchical/H_043/N_8/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_8_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/non_hierarchical/H_043/N_8/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_8_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model for $K=1$, $H=0.43$ and $N=8$.}
	\label{fig:misc_rbergomi_8_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/non_hierarchical/H_043/N_8/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_8_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/non_hierarchical/H_043/N_8/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_8_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model for $K=1$, $H=0.43$ and $N=8$.}
	\label{fig:misc_rbergomi_8_steps_2}
\end{figure}


\newpage
\subsubsection*{Case of $16$ time steps}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/non_hierarchical/H_043/N_16/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_8_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/non_hierarchical/H_043/N_16/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_8_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model for $K=1$, $H=0.43$ and $N=16$.}
	\label{fig:misc_rbergomi_8_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/non_hierarchical/H_043/N_16/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_8_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/non_hierarchical/H_043/N_16/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_8_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model for $K=1$, $H=0.43$ and $N=16$.}
	\label{fig:misc_rbergomi_8_steps_2}
\end{figure}

\newpage
\subsubsection*{H=0.07}
\newpage
\subsubsection*{Case of $8$ time steps}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/non_hierarchical/H_007/N_8/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_8_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/non_hierarchical/H_007/N_8/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_8_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model for $K=1$, $H=0.07$ and $N=8$.}
	\label{fig:misc_rbergomi_8_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/non_hierarchical/H_007/N_8/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_8_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/non_hierarchical/H_007/N_8/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_8_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model for $K=1$, $H=0.07$ and $N=8$.}
	\label{fig:misc_rbergomi_8_steps_2}
\end{figure}



\subsubsection*{Case of $16$ time steps}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/non_hierarchical/H_007/N_16/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_8_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/non_hierarchical/H_007/N_16/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_8_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model for $K=1$, $H=0.07$ and $N=16$.}
	\label{fig:misc_rbergomi_8_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/non_hierarchical/H_007/N_16/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_8_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/non_hierarchical/H_007/N_16/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_8_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model for $K=1$, $H=0.07$ and $N=16$.}
	\label{fig:misc_rbergomi_8_steps_2}
\end{figure}
\newpage
\subsection{Hierarchical}
\subsubsection*{H=0.43}
\newpage
\subsubsection*{Case of $8$ time steps}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/H_043/N_8/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_8_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/H_043/N_8/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_8_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model for $K=1$, $H=0.43$ and $N=8$.}
	\label{fig:misc_rbergomi_8_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/H_043/N_8/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_8_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/H_043/N_8/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_8_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model for $K=1$, $H=0.43$ and $N=8$.}
	\label{fig:misc_rbergomi_8_steps_2}
\end{figure}



\subsubsection*{Case of $16$ time steps}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/H_043/N_16/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_8_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/H_043/N_16/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_8_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model for $K=1$, $H=0.43$ and $N=16$.}
	\label{fig:misc_rbergomi_8_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/H_043/N_16/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_8_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/H_043/N_16/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_8_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model for $K=1$, $H=0.43$ and $N=16$.}
	\label{fig:misc_rbergomi_8_steps_2}
\end{figure}

\newpage
\subsubsection*{H=0.07}
\newpage
\subsubsection*{Case of $8$ time steps}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/H_007/N_8/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_8_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/H_007/N_8/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_8_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model for $K=1$, $H=0.07$ and $N=8$.}
	\label{fig:misc_rbergomi_8_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/H_007/N_8/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_8_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/H_007/N_8/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_8_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model for $K=1$, $H=0.07$ and $N=8$.}
	\label{fig:misc_rbergomi_8_steps_2}
\end{figure}



\subsubsection*{Case of $16$ time steps}
\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/H_007/N_16/error_estimate.pdf}
		\caption{Error estimate}
		\label{fig:misc_rbergomi_8_steps_sub1}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=1\linewidth]{./figures/bergomi_misc/H_007/N_16/average_running_time.pdf}
		\caption{Average running time as a function of $TOL$}
		\label{fig:misc_rbergomi_8_steps_sub2}
	\end{subfigure}%
	\caption{Convergence and complexity results for the call payoff with rBergomi model for $K=1$, $H=0.07$ and $N=16$.}
	\label{fig:misc_rbergomi_8_steps_1}
\end{figure}



\begin{figure}[!h]
	\centering
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/H_007/N_16/level_work.pdf}
		\caption{Average Computational time per level}
		\label{fig:misc_rbergomi_8_steps_sub3}
	\end{subfigure}%
	\begin{subfigure}{.4\textwidth}
		\centering
		\includegraphics[width=0.95\linewidth]{./figures/bergomi_misc/H_007/N_16/levels_error_rate.pdf}
		\caption{  The convergence rate of mixed differences per level}
		\label{fig:misc_rbergomi_8_steps_sub4}
	\end{subfigure}%
	\caption{Convergence and work rates for discretization levels  the call payoff with rBergomi model for $K=1$, $H=0.07$ and $N=16$.}
	\label{fig:misc_rbergomi_8_steps_2}
\end{figure}


\newpage
\subsection{Comparing call options prices }\label{sec:Comparing call options prices rbergomi}


\subsubsection{Without Hierarchical representation}
\subsubsection*{Case $H=0.43$}
\begin{table}[h!]
	\centering
	\begin{tabular}{l*{6}{c}r}
		Method \textbackslash  Steps            & $2$ & $4$ & $8$ & $16$ &   \\
		\hline
		MISC ($TOl=5.10^{-1}$)  & $0.1057$ & $0.0988$ & $0.0944$ & $0.0921$  \\
		MISC ($TOl=10^{-1}$)  & $0.1057$ & $0.0988$ & $0.0836$ & $0.0594$  \\
		MISC ($TOl=5.10^{-2}$)  & $0.1057$ & $0.0976$ & $0.0758$ & $0.0781$  \\
		MISC ($TOl=10^{-2}$)  & $0.1113$ & $0.0940$ & $0.0820$ & $-$  \\
		%		MISC ($TOl=10^{-3}$)        & $0.1081$ &$0.0918$ &  $0.0822$ &  $-$ \\
		%		MISC ($TOl=10^{-4}$)    & $0.1080$ & $0.0921$  & $-$ & $-$  \\
		%		%				MC method ($M=10^{6}$)    & $0.0840$ & $0.0781$  & $0.0746$ & $0.0729$  \\
		MC method ($M=10^{6}$)   & $\underset{(1.55e-04)}{0.1079}$ & $ \underset{(9.65e-05)}{0.0921}$  & $ \underset{(7.61e-05)}{0.0822}$ & $ \underset{(6.65e-05)}{0.0769}$ \\		
		
		\hline
	\end{tabular}
	\caption{ Call option price of the different methods for different number of time steps. Case $K=1$}
	\label{table: Call option price of the different methods for different number of time steps. Case $K=1$}
\end{table}


\subsubsection*{Case $H=0.07$}

\begin{table}[h!]
	\centering
	\begin{tabular}{l*{6}{c}r}
		Method \textbackslash  Steps            & $2$ & $4$ & $8$ & $16$  \\
		\hline
		MISC ($TOl=5.10^{-1}$)  & $0.1065$ & $0.0900$ & $0.0809$ & $0.0762$  \\
		MISC ($TOl=10^{-1}$)  &  $0.1065$ &   $0.0900$ & $0.0733$ & $0.0956$  \\
		MISC ($TOl=5.10^{-2}$)        &  $0.1065$ &$0.0898$ &  $0.0881$ &  $-$ \\
		MISC ($TOl=10^{-2}$)    & $0.1226$ & $0.1022$  & $0.0933$ & $-$  \\
		%				MC method ($M=10^{6}$)    & $0.0840$ & $0.0781$  & $0.0746$ & $0.0729$  \\
		MC method ($M=10^{6}$)   & $\underset{(1.05e-03)}{0.1216} $  & $\underset{(1.86e-04)}{0.1020} $  & $\underset{ (1.35e-04)}{0.0912}$ & $\underset {(1.08e-04)}{0.0854} $  \\		
		\hline
	\end{tabular}
	\caption{ Call option price of the different methods for different number of time steps. Case $K=1$}
	\label{table: Call option price of the different methods for different number of time steps. Case $K=1$_H_007}
\end{table}



%where $\sum_{t_1,t_2}= \sum_{t_1=1}^{N_1}  \sum_{t_1=1}^{N_2}$, being the number of quadrature points selected for each direction, $\mathbf{u}^\ast= (u_{t_1}^\ast,u_{t_2}^\ast)^T= \sqrt{2} L (u_{t_1},u_{t_2})^T+\hat{\mathbf{u}}$ and $w^\ast_{t_i}=w_{t_i} \exp[u_{t_i}^2]$ are  the new Gauss-Hermite nodes and weights, based on importance sampling, respectively, with $u_{t_k}$ being the classical
%Gauss-Hermite nodes and $w_{t_k} , k = 1,2$, the corresponding weights.
%
\end{document}