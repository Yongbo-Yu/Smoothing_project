\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{bungartz2004sparse}
\citation{griebel2013smoothing}
\citation{bayersmoothing}
\citation{griebel2017note}
\citation{griewank2017high}
\citation{xiao2018conditional}
\citation{griebel2013smoothing}
\citation{griebel2017note}
\citation{griewank2017high}
\citation{griebel2013smoothing}
\citation{griebel2017note}
\citation{griewank2017high}
\citation{griebel2013smoothing}
\citation{griebel2017note}
\citation{griebel2013smoothing}
\citation{griebel2017note}
\citation{griebel2013smoothing}
\citation{griebel2017note}
\citation{griewank2017high}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{xiao2018conditional}
\citation{bayersmoothing}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem formulation and Setting}{2}{section.2}}
\newlabel{sec:General setting}{{2}{2}{Problem formulation and Setting}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Continuous time formulation}{2}{subsection.2.1}}
\newlabel{eq:SDE_interest}{{2.1}{2}{Continuous time formulation}{equation.2.1}{}}
\newlabel{eq:smoothing_decomposition}{{2.3}{2}{Continuous time formulation}{equation.2.3}{}}
\newlabel{eq:smoothing_decomposition_componentwise}{{2.4}{2}{Continuous time formulation}{equation.2.4}{}}
\newlabel{optimality_criterion_2}{{2.5}{3}{Continuous time formulation}{equation.2.5}{}}
\newlabel{eq:SDE_decomposition_componentwise_exapanded}{{2.7}{3}{Continuous time formulation}{equation.2.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}First approach (Brutal)}{3}{subsubsection.2.1.1}}
\newlabel{eq: variance global terms}{{2.8}{4}{First approach (Brutal)}{equation.2.8}{}}
\newlabel{eq:approximate_dynamics}{{2.9}{4}{First approach (Brutal)}{equation.2.9}{}}
\newlabel{eq:first_moment_approximation}{{2.11}{4}{First approach (Brutal)}{equation.2.11}{}}
\newlabel{eq:second_moment_approximation}{{2.12}{5}{First approach (Brutal)}{equation.2.12}{}}
\newlabel{eq:covariance_dynamcis_approximation}{{2.13}{5}{First approach (Brutal)}{equation.2.13}{}}
\newlabel{eq:call_option}{{2.14}{5}{First approach (Brutal)}{equation.2.14}{}}
\newlabel{eq:binary_option}{{2.15}{6}{First approach (Brutal)}{equation.2.15}{}}
\newlabel{assump:Monotonicity condition}{{2.16}{6}{First approach (Brutal)}{equation.2.16}{}}
\newlabel{assump:Growth condition}{{2.17}{6}{First approach (Brutal)}{equation.2.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Discrete time formulation}{6}{subsection.2.2}}
\newlabel{sec:Discrete time, practical motivation}{{2.2}{6}{Discrete time formulation}{subsection.2.2}{}}
\newlabel{lognormal_dynamics_basket}{{2.19}{7}{Discrete time formulation}{equation.2.19}{}}
\newlabel{eq: option price as integral_basket}{{2.20}{7}{Discrete time formulation}{equation.2.20}{}}
\newlabel{eq:discrete_rep}{{2.21}{7}{Discrete time formulation}{equation.2.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Step $1$: Numerical smoothing}{7}{subsubsection.2.2.1}}
\newlabel{sec:Step $1$: Numerical smoothing}{{2.2.1}{7}{Step $1$: Numerical smoothing}{subsubsection.2.2.1}{}}
\newlabel{eq:linear_transformation}{{2.22}{8}{Step $1$: Numerical smoothing}{equation.2.22}{}}
\newlabel{eq:discrete_rep_2}{{2.23}{8}{Step $1$: Numerical smoothing}{equation.2.23}{}}
\newlabel{eq: incremental functions}{{2.24}{8}{Step $1$: Numerical smoothing}{equation.2.24}{}}
\newlabel{polynomial_kink_location_basket}{{2.26}{8}{Step $1$: Numerical smoothing}{equation.2.26}{}}
\newlabel{polynomial_kink_location_derivative_basket}{{2.27}{8}{Step $1$: Numerical smoothing}{equation.2.27}{}}
\newlabel{transformation_optimality_criterion}{{2.28}{8}{}{equation.2.28}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Step $2$: Integration}{9}{subsubsection.2.2.2}}
\newlabel{sec:Step $2$: Integration}{{2.2.2}{9}{Step $2$: Integration}{subsubsection.2.2.2}{}}
\newlabel{eq: pre_integration_step_wrt_y1_basket}{{2.29}{9}{Step $2$: Integration}{equation.2.29}{}}
\newlabel{eq:smooth_function_after_pre_integration}{{2.30}{9}{Step $2$: Integration}{equation.2.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Analiticity Analysis}{9}{section.3}}
\newlabel{sec:Analiticity Analysis}{{3}{9}{Analiticity Analysis}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Haar construction of Brownian motion revisited}{9}{subsection.3.1}}
\newlabel{sec:haar-constr-brown}{{3.1}{9}{Haar construction of Brownian motion revisited}{subsection.3.1}{}}
\newlabel{eq:Haar-mother}{{3.1}{10}{Haar construction of Brownian motion revisited}{equation.3.1}{}}
\newlabel{eq:Haar-basis}{{3.2}{10}{Haar construction of Brownian motion revisited}{equation.3.2}{}}
\newlabel{eq:Haar-constant}{{3.2a}{10}{Haar construction of Brownian motion revisited}{equation.3.2a}{}}
\newlabel{eq:Haar-nonconstant}{{3.2b}{10}{Haar construction of Brownian motion revisited}{equation.3.2b}{}}
\newlabel{eq:Haar-int-basis}{{3.3}{10}{Haar construction of Brownian motion revisited}{equation.3.3}{}}
\newlabel{eq:Haar-int-constant}{{3.3a}{10}{Haar construction of Brownian motion revisited}{equation.3.3a}{}}
\newlabel{eq:Haar-int-nonconstant}{{3.3b}{10}{Haar construction of Brownian motion revisited}{equation.3.3b}{}}
\newlabel{eq:Brownian-motion}{{3.4}{10}{Haar construction of Brownian motion revisited}{equation.3.4}{}}
\newlabel{eq:Brownian-motion-truncated}{{3.5}{10}{Haar construction of Brownian motion revisited}{equation.3.5}{}}
\newlabel{eq:increments}{{3.6}{10}{Haar construction of Brownian motion revisited}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Stochastic differential equations}{10}{subsection.3.2}}
\newlabel{sec:stoch-diff-equat}{{3.2}{10}{Stochastic differential equations}{subsection.3.2}{}}
\newlabel{eq:SDE}{{3.7}{10}{Stochastic differential equations}{equation.3.7}{}}
\newlabel{eq:euler}{{3.8}{11}{Stochastic differential equations}{equation.3.8}{}}
\newlabel{eq:H-function}{{3.9}{11}{Stochastic differential equations}{equation.3.9}{}}
\newlabel{eq:1}{{3.10}{11}{Stochastic differential equations}{equation.3.10}{}}
\newlabel{ass:boundedness-derivative}{{3.1}{12}{}{theorem.3.1}{}}
\newlabel{ass:boundedness-inverse}{{3.3}{12}{}{theorem.3.3}{}}
\newlabel{lem:dXdZ}{{3.4}{12}{}{theorem.3.4}{}}
\newlabel{eq:dWdZ}{{3.11}{12}{Stochastic differential equations}{equation.3.11}{}}
\newlabel{eq:2}{{3.12}{12}{Stochastic differential equations}{equation.3.12}{}}
\newlabel{lem:d2XdZdY}{{3.5}{13}{}{theorem.3.5}{}}
\newlabel{eq:d2XdWdW}{{3.13}{13}{Stochastic differential equations}{equation.3.13}{}}
\newlabel{prop:first-derivatives}{{3.7}{13}{}{theorem.3.7}{}}
\newlabel{lem:d2XdZ2}{{3.8}{14}{}{theorem.3.8}{}}
\newlabel{thr:smoothness}{{3.9}{14}{}{theorem.3.9}{}}
\newlabel{rem:analyticity}{{3.10}{14}{}{theorem.3.10}{}}
\citation{haji2016multi}
\@writefile{toc}{\contentsline {section}{\numberline {4}Details of our hierarchical method}{15}{section.4}}
\newlabel{sec:Details of our approach}{{4}{15}{Details of our hierarchical method}{section.4}{}}
\newlabel{eq:total_error}{{4.1}{15}{Details of our hierarchical method}{equation.4.1}{}}
\citation{bungartz2004sparse}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}The MISC method}{16}{subsection.4.1}}
\newlabel{sec:Details of the MISC}{{4.1}{16}{The MISC method}{subsection.4.1}{}}
\citation{morokoff1994quasi}
\citation{moskowitz1996smoothness}
\citation{caflisch1997valuation}
\citation{acworth1998comparison}
\citation{imai2004minimizing}
\newlabel{eq:MISC_quad_estimator}{{4.2}{17}{The MISC method}{equation.4.2}{}}
\newlabel{eq:quadrature error}{{4.3}{17}{The MISC method}{equation.4.3}{}}
\newlabel{eq:Work_error_contributions}{{4.4}{17}{The MISC method}{equation.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Brownian bridge (Bb) construction}{17}{subsection.4.2}}
\newlabel{sec:Brwonian bridge construction}{{4.2}{17}{Brownian bridge (Bb) construction}{subsection.4.2}{}}
\citation{glasserman2004monte}
\citation{talay1990expansion}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Richardson extrapolation}{18}{subsection.4.3}}
\newlabel{sec:Richardson extrapolation}{{4.3}{18}{Richardson extrapolation}{subsection.4.3}{}}
\newlabel{Euler_weak_error_strenghten}{{4.5}{18}{Richardson extrapolation}{equation.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Root Finding}{18}{subsection.4.4}}
\newlabel{sec: Root Finding}{{4.4}{18}{Root Finding}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Error discussion}{19}{section.5}}
\newlabel{sec:Error discussion}{{5}{19}{Error discussion}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Errors in smoothing}{19}{subsection.5.1}}
\newlabel{sec:errors-smoothing}{{5.1}{19}{Errors in smoothing}{subsection.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Numerical experiments}{20}{section.6}}
\newlabel{optimal_number_samples}{{6.1}{21}{Numerical experiments}{Item.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces Summary of relative errors and computational gains, achieved by the different methods. In this table, we highlight the computational gains achieved by MISC over MC method to meet a certain error tolerance. We provide details about the way we compute these gains for each case in the following sections.\relax }}{21}{table.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table:Summary of our numerical results.}{{6.1}{21}{Summary of relative errors and computational gains, achieved by the different methods. In this table, we highlight the computational gains achieved by MISC over MC method to meet a certain error tolerance. We provide details about the way we compute these gains for each case in the following sections.\relax }{table.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Options under the discretized one dimensional GBM model}{21}{subsection.6.1}}
\newlabel{sec:The discretized 1D Black-Scholes}{{6.1}{21}{Options under the discretized one dimensional GBM model}{subsection.6.1}{}}
\newlabel{lognormal_dynamics}{{6.2}{21}{Options under the discretized one dimensional GBM model}{equation.6.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Determining the kink location}{22}{subsubsection.6.1.1}}
\newlabel{sec:Determining the kink location}{{6.1.1}{22}{Determining the kink location}{subsubsection.6.1.1}{}}
\newlabel{eq: kink_point_problem}{{6.4}{22}{Exact location of the kink for the continuous problem}{equation.6.4}{}}
\newlabel{xact_location_continuous_problem}{{6.6}{22}{Exact location of the kink for the continuous problem}{equation.6.6}{}}
\newlabel{polynomial_kink_location}{{6.10}{22}{Location of the kink for the discrete problem}{equation.6.10}{}}
\newlabel{polynomial_kink_location_derivative}{{6.11}{23}{Location of the kink for the discrete problem}{equation.6.11}{}}
\newlabel{smoothed_integrand_single_opt_1d}{{6.12}{23}{Location of the kink for the discrete problem}{equation.6.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.2}Results for the single binary option under discretized GBM model}{23}{subsubsection.6.1.2}}
\newlabel{sec:Results for the binary option example}{{6.1.2}{23}{Results for the single binary option under discretized GBM model}{subsubsection.6.1.2}{}}
\newlabel{smoothed_integrand_binary_opt_2}{{6.14}{23}{Results for the single binary option under discretized GBM model}{equation.6.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces The rate of convergence of the weak error for the binary option, using $M=10^4$ samples for MC.\relax }}{24}{figure.caption.4}}
\newlabel{fig:Weak_rate_binary}{{6.1}{24}{The rate of convergence of the weak error for the binary option, using $M=10^4$ samples for MC.\relax }{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.2}{\ignorespaces Total relative error of MISC, with different tolerances, and MC to compute binary option price for different number of time steps, without Richardson extrapolation. The values marked in red, for MISC method, correspond to the total relative errors associated with stable quadrature errors for MISC, and will be used for complexity comparison against MC.\relax }}{24}{table.caption.5}}
\newlabel{Total error of MISC and MC to compute Binary option price of the different tolerances for different number of time steps, without Richardson extrapolation. The numbers between parentheses are the corresponding absolute errors.}{{6.2}{24}{Total relative error of MISC, with different tolerances, and MC to compute binary option price for different number of time steps, without Richardson extrapolation. The values marked in red, for MISC method, correspond to the total relative errors associated with stable quadrature errors for MISC, and will be used for complexity comparison against MC.\relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.3}{\ignorespaces Comparison of the computational time of MC and MISC, used to compute binary option price for different number of time steps, without Richardson extrapolation. The average computational time of MC is computed over $10$ runs.\relax }}{24}{table.caption.6}}
\newlabel{Comparsion of the computational time of MC and MISC, used to compute Binary option price for different number of time steps, without Richardson extrapolation}{{6.3}{24}{Comparison of the computational time of MC and MISC, used to compute binary option price for different number of time steps, without Richardson extrapolation. The average computational time of MC is computed over $10$ runs.\relax }{table.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Complexity plot for MC and MISC for the case without Richardson extrapolation.\relax }}{25}{figure.caption.7}}
\newlabel{fig:Complexity plot for MC and MISC , Binary, Non rich}{{6.2}{25}{Complexity plot for MC and MISC for the case without Richardson extrapolation.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Results for the single call option example}{25}{subsection.6.2}}
\newlabel{sec:Results for the call option example}{{6.2}{25}{Results for the single call option example}{subsection.6.2}{}}
\newlabel{smoothed_integrand_call_opt_2}{{6.16}{25}{Results for the single call option example}{equation.6.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces The rate of convergence of the weak error for the call option using MC.\relax }}{26}{figure.caption.8}}
\newlabel{fig:Weak_rate_call_beta_32}{{6.3}{26}{The rate of convergence of the weak error for the call option using MC.\relax }{figure.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.4}{\ignorespaces Total relative error of MISC, with different tolerances, and MC to compute call option price for different number of time steps, without Richardson extrapolation. The values marked in red, for MISC method, correspond to the total relative errors associated with stable quadrature errors for MISC, and will be used for complexity comparison against MC.\relax }}{26}{table.caption.9}}
\newlabel{Total error of MISC and MC to compute Call option price of the different tolerances for different number of time steps, without Richardson extrapolation. The numbers between parentheses are the corresponding absolute errors.}{{6.4}{26}{Total relative error of MISC, with different tolerances, and MC to compute call option price for different number of time steps, without Richardson extrapolation. The values marked in red, for MISC method, correspond to the total relative errors associated with stable quadrature errors for MISC, and will be used for complexity comparison against MC.\relax }{table.caption.9}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.5}{\ignorespaces Comparison of the computational time of MC and MISC, used to compute call option price for different number of time steps, without Richardson extrapolation. The average computational time of MC is computed over $10$ runs.\relax }}{26}{table.caption.10}}
\newlabel{Comparsion of the computational time of MC and MISC, used to compute Call option price for different number of time steps, without Richardson extrapolation}{{6.5}{26}{Comparison of the computational time of MC and MISC, used to compute call option price for different number of time steps, without Richardson extrapolation. The average computational time of MC is computed over $10$ runs.\relax }{table.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Complexity plot for MC and MISC for the case without Richardson extrapolation.\relax }}{27}{figure.caption.11}}
\newlabel{fig:Complexity plot for MC and MISC , Call non rich}{{6.4}{27}{Complexity plot for MC and MISC for the case without Richardson extrapolation.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}The basket call option under GBM model}{27}{subsection.6.3}}
\newlabel{sec:The basket call option under GBM model}{{6.3}{27}{The basket call option under GBM model}{subsection.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}$d=2$}{27}{subsection.6.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces The rate of convergence of the weak error for the two dimensional basket call option with a number of Laguerre quadrature points $\beta =128$ and number of samples for MC $M=10^7$. \relax }}{27}{figure.caption.12}}
\newlabel{fig:Weak_rate_two_dim_basket}{{6.5}{27}{The rate of convergence of the weak error for the two dimensional basket call option with a number of Laguerre quadrature points $\beta =128$ and number of samples for MC $M=10^7$. \relax }{figure.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.6}{\ignorespaces Total relative error of MISC, with different tolerances, and MC to compute two dimensional basket call option price for different number of time steps, without Richardson extrapolation. The values marked in red, for MISC method, correspond to the total relative errors associated with stable quadrature errors for MISC, and will be used for complexity comparison against MC.\relax }}{28}{table.caption.13}}
\newlabel{Total error of MISC and MC to compute two dim basket Call option price of the different tolerances for different number of time steps, without Richardson extrapolation. The numbers between parentheses are the corresponding absolute errors.}{{6.6}{28}{Total relative error of MISC, with different tolerances, and MC to compute two dimensional basket call option price for different number of time steps, without Richardson extrapolation. The values marked in red, for MISC method, correspond to the total relative errors associated with stable quadrature errors for MISC, and will be used for complexity comparison against MC.\relax }{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6.7}{\ignorespaces Comparison of the computational time of MC and MISC, used to compute two dimensional basket call option price for different number of time steps, without Richardson extrapolation. The average computational time of MC is computed over $10$ runs.\relax }}{28}{table.caption.14}}
\newlabel{Comparsion of the computational time of MC and MISC, used to compute two dim basket Call option price for different number of time steps, without Richardson extrapolation}{{6.7}{28}{Comparison of the computational time of MC and MISC, used to compute two dimensional basket call option price for different number of time steps, without Richardson extrapolation. The average computational time of MC is computed over $10$ runs.\relax }{table.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Complexity plot for MC and MISC for the case without Richardson extrapolation.\relax }}{28}{figure.caption.15}}
\newlabel{fig:Complexity plot for MC and MISC , Call non rich}{{6.6}{28}{Complexity plot for MC and MISC for the case without Richardson extrapolation.\relax }{figure.caption.15}{}}
\bibstyle{plain}
\bibdata{smoothing}
\bibcite{acworth1998comparison}{1}
\bibcite{bayersmoothing}{2}
\bibcite{bungartz2004sparse}{3}
\bibcite{caflisch1997valuation}{4}
\bibcite{glasserman2004monte}{5}
\bibcite{griebel2013smoothing}{6}
\bibcite{griebel2017note}{7}
\bibcite{griewank2017high}{8}
\bibcite{haji2016multi}{9}
\bibcite{imai2004minimizing}{10}
\bibcite{morokoff1994quasi}{11}
\bibcite{moskowitz1996smoothness}{12}
\bibcite{talay1990expansion}{13}
\bibcite{xiao2018conditional}{14}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}$d=4$}{29}{subsection.6.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}The best call option under GBM and Heston model}{29}{subsection.6.6}}
\newlabel{sec:The best call option under GBM and Heston model}{{6.6}{29}{The best call option under GBM and Heston model}{subsection.6.6}{}}
